@article{abbot-smith2016,
  title = {How Children Aged 2;6 Tailor Verbal Expressions to Interlocutor Informational Needs},
  author = {{Abbot-Smith}, Kirsten and Nurmsoo, Erika and Croll, Rebecca and Ferguson, Heather and Forrester, Michael},
  year = {2016},
  month = nov,
  journal = {Journal of Child Language},
  volume = {43},
  number = {6},
  pages = {1277--1291},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000915000616},
  urldate = {2022-06-08},
  abstract = {Although preschoolers are pervasively underinformative in their actual usage of verbal reference, a number of studies have shown that they nonetheless demonstrate sensitivity to listener informational needs, at least when environmental cues to this are obvious. We investigated two issues. The first concerned the types of visual cues to interlocutor informational needs which children aged ; can process whilst producing complex referring expressions. The second was whether performance in experimental tasks related to naturalistic conversational proficiency. We found that ;-year-olds used fewer complex expressions when the objects were dissimilar compared to highly similar objects, indicating that they tailor their verbal expressions to the informational needs of another person, even when the cue to the informational need is relatively opaque. We also found a correlation between conversational skills as rated by the parents and the degree to which ;-year-olds could learn from feedback to produce complex referring expressions.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/X7T5BII8/Abbot-Smith et al. - 2016 - How children aged 2;6 tailor verbal expressions to.pdf}
}

@article{ahern1994,
  title = {The Effect of Interface on the Structure of Interaction in Computer-Mediated Small-Group Discussion},
  author = {Ahern, Terence C},
  year = {1994},
  journal = {Journal of Educational Computing Research},
  volume = {11},
  number = {3},
  pages = {235--250},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{almaatouq2020,
  ids = {almaatouqEmpiricaVirtualLab2021},
  title = {Empirica: A Virtual Lab for High-Throughput Macro-Level Experiments},
  shorttitle = {Empirica},
  author = {Almaatouq, Abdullah and Becker, Joshua and Houghton, James P. and Paton, Nicolas and Watts, Duncan J. and Whiting, Mark E.},
  year = {2020},
  month = dec,
  journal = {arXiv:2006.11398 [cs]},
  eprint = {2006.11398},
  primaryclass = {cs},
  urldate = {2021-02-09},
  abstract = {Virtual labs allow researchers to design high-throughput and macro-level experiments that are not feasible in traditional in-person physical lab settings. Despite the increasing popularity of online research, researchers still face many technical and logistical barriers when designing and deploying virtual lab experiments. While several platforms exist to facilitate the development of virtual lab experiments, they typically present researchers with a stark trade-off between usability and functionality. We introduce Empirica: a modular virtual lab that offers a solution to the usability-functionality trade-off by employing a "flexible defaults" design strategy. This strategy enables us to maintain complete "build anything" flexibility while offering a development platform that is accessible to novice programmers. Empirica's architecture is designed to allow for parameterizable experimental designs, reusable protocols, and rapid development. These features will increase the accessibility of virtual lab experiments, remove barriers to innovation in experiment design, and enable rapid progress in the understanding of distributed human computation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Social and Information Networks,read},
  file = {/home/vboyce/Zotero/storage/B2YTU5DD/Almaatouq et al. - 2021 - Empirica a virtual lab for high-throughput macro-.pdf;/home/vboyce/Zotero/storage/F5F32FWZ/Almaatouq et al. - 2020 - Empirica a virtual lab for high-throughput macro-.pdf;/home/vboyce/Zotero/storage/XUB3HJJ5/Almaatouq et al. - 2021 - Empirica a virtual lab for high-throughput macro-.pdf;/home/vboyce/Zotero/storage/R2LIXB8W/2006.html}
}

@article{almaatouq2024,
  title = {Beyond Playing 20 Questions with Nature: {{Integrative}} Experiment Design in the Social and Behavioral Sciences},
  shorttitle = {Beyond Playing 20 Questions with Nature},
  author = {Almaatouq, Abdullah and Griffiths, Thomas L. and Suchow, Jordan W. and Whiting, Mark E. and Evans, James and Watts, Duncan J.},
  year = {2024},
  journal = {Behavioral and Brain Sciences},
  volume = {47},
  pages = {e33},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X22002874},
  urldate = {2024-03-16},
  abstract = {The dominant paradigm of experiments in the social and behavioral sciences views an experiment as a test of a theory, where the theory is assumed to generalize beyond the experiment's specific conditions. According to this view, which Alan Newell once characterized as ``playing twenty questions with nature,'' theory is advanced one experiment at a time, and the integration of disparate findings is assumed to happen via the scientific publishing process. In this article, we argue that the process of integration is at best inefficient, and at worst it does not, in fact, occur. We further show that the challenge of integration cannot be adequately addressed by recently proposed reforms that focus on the reliability and replicability of individual findings, nor simply by conducting more or larger experiments. Rather, the problem arises from the imprecise nature of social and behavioral theories and, consequently, a lack of commensurability across experiments conducted under different conditions. Therefore, researchers must fundamentally rethink how they design experiments and how the experiments relate to theory. We specifically describe an alternative framework, integrative experiment design, which intrinsically promotes commensurability and continuous integration of knowledge. In this paradigm, researchers explicitly map the design space of possible experiments associated with a given research question, embracing many potentially relevant theories rather than focusing on just one. Researchers then iteratively generate theories and test them with experiments explicitly sampled from the design space, allowing results to be integrated across experiments. Given recent methodological and technological developments, we conclude that this approach is feasible and would generate more-reliable, more-cumulative empirical and theoretical knowledge than the current paradigm -- and with far greater efficiency.},
  langid = {english},
  keywords = {(in)commensurability,cumulative knowledge,experiments,generalizability,read,useful},
  file = {/home/vboyce/Zotero/storage/ZA7GZG76/Almaatouq et al. - 2024 - Beyond playing 20 questions with nature Integrati.pdf}
}

@article{bates1974,
  title = {Acquisition of Pragmatic Competence},
  author = {Bates, Elizabeth},
  year = {1974},
  month = nov,
  journal = {Journal of Child Language},
  volume = {1},
  number = {2},
  pages = {277--281},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900000702},
  urldate = {2025-01-16},
  abstract = {The following describes a study of the acquisition of `pragmatic' structures by Italian children. PRAGMATICS refers to the study of the use of language in context, by real speakers and hearers in real situations. It therefore fails to meet the definition of `competence' outlined by Chomsky, emphasizing the ideal speaker abstracted from particular situations, and perhaps for this reason has been neglected in psycholinguistic studies. However, there has been a renewed interest in pragmatics in recent semantic theory, and a number of proposals have been made regarding a formal representation for pragmatic structures. Three major positions can be distinguished, all of which in varying degrees separate pragmatics from the propositional content itself, as a set of procedures and assumptions for the appropriate use of propositions. Interpretive semanticists, such as Jackendoff (1972), place pragmatics entirely outside the syntactic component, in a separate and heterogeneous semantic component. Fillmore (1968) and Weinreich (1963) offer proposals for a separate `modality component' which operates on a more articulated semantic structure. For example, in the sentence               Could John have hit the ball               ?, the proposition `John hit the ball' is spelled out in terms of the predicate `hit', the two arguments, and the semantic relations holding among them. The modality component would contain simply a set of unanalysed symbols like QUESTION, CONDITIONAL and PAST PERFECT that are applied to the proposition. A third approach to pragmatics is offered in natural logic models like those of Parisi \& Antinucci (1973) or Lakoff (forthcoming). In these models, as contrasted with the above modality component, all the meaning underlying a sentence is broken into minimal elements. Thus the above sentence is described not only with the nuclear proposition `John hit the ball', but with a performative proposition describing the speaker's interrogative intention (i.e. `I ask you{\dots}') and with various presuppositions               1               describing the conditions that are necessary for the sentence to be appropriate. For example, instead of an unanalysed symbol for conditional, there is an ancillary proposition describing the fact that the central proposition is not necessarily true at time X. This latter approach was of more heuristic value for a developmental study of pragmatics because a representation is available for all the meaning underlying a given sentence. For example, the articulated presupposition `Proposition X is not necessarily true at time X' is more easily translatable into psychological terms than an unanalysed symbol like `Conditional'.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/E6U7GGC4/Bates - 1974 - Acquisition of pragmatic competence.pdf}
}

@inproceedings{baumann2014,
  title = {Overspecification and the {{Cost}} of {{Pragmatic Reasoning}} about {{Referring Expressions}}},
  booktitle = {Proceedings of the {{Annual Meeting}} of the {{Cognitive Science Society}}},
  author = {Baumann, Peter and Clark, Brady and Kaufmann, Stefan},
  year = {2014},
  volume = {36},
  abstract = {In current approaches to pragmatic reasoning the comprehension and production of referring expressions is modeled as a result of the interlocutors' mutual perspective-taking under the additional assumption that speakers try to minimize their articulatory effort or production cost. The latter assumption is usually not tested and instead built into the experimental tasks of referential language games by artificially restricting the set of possible referring expressions available to identify a referent. We present two language game experiments: a production experiment, in which the speakers were allowed to freely choose a referring expression, and a comprehension experiment to replicate earlier findings with our stimuli. Our results show that while listeners easily perform pragmatic reasoning, speakers resort to overspecification when the effort of pragmatic reasoning becomes too high.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/LYTN8NP6/Baumann et al. - Overspeciﬁcation and the Cost of Pragmatic Reasoni.pdf}
}

@article{bergen2016,
  title = {Pragmatic Reasoning through Semantic Inference},
  author = {Bergen, Leon and Levy, Roger and Goodman, Noah},
  year = {2016},
  journal = {Semantics and Pragmatics},
  pages = {84},
  abstract = {A number of recent proposals have used techniques from game theory and Bayesian cognitive science to formalize Gricean pragmatic reasoning (Franke 2009, Frank \& Goodman 2012, Goodman \& Stuhlm{\"u}ller 2013, J{\"a}ger 2012). We discuss two phenomena which pose a challenge to these accounts of pragmatics: M-implicatures (Horn 1984) and embedded implicatures which violate Hurford's constraint (Hurford 1974, Chierchia et al. 2012). While techniques have been developed for deriving M-implicatures, Hurford-violating embedded implicatures pose a more fundamental challenge, because of basic limitations in the models' architecture. In order to explain these phenomena, we propose a realignment of the division between semantic content and pragmatic content. Under this proposal, the semantic content of an utterance is not fixed independent of pragmatic inference; rather, pragmatic inference partially determines an utterance's semantic content. We show how semantic inference can be realized as an extension to the Rational Speech Acts framework (Goodman \& Stuhlm{\"u}ller 2013). The addition of lexical uncertainty derives both M-implicatures and the relevant embedded implicatures, and preserves the derivations of more standard implicatures. We use this principle to explain a novel class of implicature, non-convex disjunctive implicatures, which have several theoretically interesting properties. In particular, these implicatures can be preserved in downward-entailing contexts in the absence of accenting, a property which is predicted by lexical uncertainty, but which violates prior generalizations in the literature (Horn 1989, Fox \& Spector Forthcoming).},
  langid = {english},
  keywords = {Bayesian modeling,Division of pragmatic labor,Embedded implicatures,Game theory,Hurford's constraint,Pragmatics,read},
  file = {/home/vboyce/Zotero/storage/5T3YRMR2/Bergen et al. - Pragmatic reasoning through semantic inference.pdf;/home/vboyce/Zotero/storage/FYYVXM63/Bergen et al. - 2016 - Pragmatic reasoning through semantic inference.pdf;/home/vboyce/Zotero/storage/WW867M2B/Bergen et al. - 2016 - Pragmatic reasoning through semantic inference.pdf}
}

@article{bohn2019,
  title = {Young Children Spontaneously Recreate Core Properties of Language in a New Modality},
  author = {Bohn, Manuel and Kachel, Gregor and Tomasello, Michael},
  year = {2019},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {51},
  pages = {26072--26077},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1904871116},
  urldate = {2025-01-06},
  abstract = {How the world's 6,000+ natural languages have arisen is mostly unknown. Yet, new sign languages have emerged recently among deaf people brought together in a community, offering insights into the dynamics of language evolution. However, documenting the emergence of these languages has mostly consisted of studying the end product; the process by which ad hoc signs are transformed into a structured communication system has not been directly observed. Here we show how young children create new communication systems that exhibit core features of natural languages in less than 30 min. In a controlled setting, we blocked the possibility of using spoken language. In order to communicate novel messages, including abstract concepts, dyads of children spontaneously created novel gestural signs. Over usage, these signs became increasingly arbitrary and conventionalized. When confronted with the need to communicate more complex meanings, children began to grammatically structure their gestures. Together with previous work, these results suggest that children have the basic skills necessary, not only to acquire a natural language, but also to spontaneously create a new one. The speed with which children create these structured systems has profound implications for theorizing about language evolution, a process which is generally thought to span across many generations, if not millennia.},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/QLT6GAL4/Bohn et al. - 2019 - Young children spontaneously recreate core properties of language in a new modality.pdf}
}

@article{bohn2019a,
  title = {The Pervasive Role of Pragmatics in Early Language},
  author = {Bohn, Manuel and Frank, Michael C.},
  year = {2019},
  month = jun,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/v8e56},
  urldate = {2020-08-31},
  abstract = {Language is a fundamentally social endeavor. Pragmatics is the study of how speakers and listeners use social reasoning to go beyond the literal meanings of words to interpret language in context. In this review, we take a pragmatic perspective on language development and argue for developmental continuity between early non-verbal communication, language learning, and linguistic pragmatics. We link phenomena from these different literatures by relating them to a computational framework (the rational speech act framework), which conceptualizes communication as fundamentally inferential and grounded in social cognition. The model specifies how different information sources (linguistic utterances, social cues, common ground) are combined when making pragmatic inferences. We present evidence in favor of this inferential view and review how pragmatic reasoning supports children's learning, comprehension, and use of language.},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/2S4J5TGP/Bohn and Frank - 2019 - The pervasive role of pragmatics in early language.pdf;/home/vboyce/Zotero/storage/WJ4ZBLRL/Bohn and Frank - The Pervasive Role of Pragmatics in Early Language.pdf;/home/vboyce/Zotero/storage/2EWXDVVG/v8e56.html}
}

@article{bohn2022,
  title = {Modeling {{Individual Differences}} in {{Children}}'s {{Information Integration During Pragmatic Word Learning}}},
  author = {Bohn, Manuel and Schmidt, Louisa S. and Schulze, Cornelia and Frank, Michael C. and Tessler, Michael Henry},
  year = {2022},
  month = dec,
  journal = {Open Mind},
  volume = {6},
  pages = {311--326},
  issn = {2470-2986},
  doi = {10.1162/opmi_a_00069},
  urldate = {2025-02-01},
  abstract = {Pragmatics is foundational to language use and learning. Computational cognitive models have been successfully used to predict pragmatic phenomena in adults and children -- on an aggregate level. It is unclear if they can be used to predict behavior on an individual level. We address this question in children (N = 60, 3- to 5-year-olds), taking advantage of recent work on pragmatic cue integration. In Part 1, we use data from four independent tasks to estimate child-specific sensitivity parameters to three information sources: semantic knowledge, expectations about speaker informativeness, and sensitivity to common ground. In Part 2, we use these parameters to generate participant-specific trial-by-trial predictions for a new task that jointly manipulated all three information sources. The model accurately predicted children's behavior in the majority of trials. This work advances a substantive theory of individual differences in which the primary locus of developmental variation is sensitivity to individual information sources.},
  file = {/home/vboyce/Zotero/storage/DQNA5WXX/Bohn et al. - 2022 - Modeling Individual Differences in Children’s Information Integration During Pragmatic Word Learning.pdf;/home/vboyce/Zotero/storage/FQMQ4INL/Modeling-Individual-Differences-in-Children-s.html}
}

@article{boyce2024,
  title = {Interaction Structure Constrains the Emergence of Conventions in Group Communication},
  author = {Boyce, Veronica and Hawkins, Robert D. and Goodman, Noah D. and Frank, Michael C.},
  year = {2024},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {28},
  pages = {e2403888121},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2403888121},
  urldate = {2025-01-07},
  abstract = {Real-world communication frequently requires language producers to address more than one comprehender at once, yet most psycholinguistic research focuses on one-on-one communication. As the audience size grows, interlocutors face new challenges that do not arise in dyads. They must consider multiple perspectives and weigh multiple sources of feedback to build shared understanding. Here, we ask which properties of the group's interaction structure facilitate successful communication. We used a repeated reference game paradigm in which directors instructed between one and five matchers to choose specific targets out of a set of abstract figures. Across 313 games (               N               = 1,319 participants), we manipulated several key constraints on the group's interaction, including the amount of feedback that matchers could give to directors and the availability of peer interaction between matchers. Across groups of different sizes and interaction constraints, describers produced increasingly efficient utterances and matchers made increasingly accurate selections. Critically, however, we found that smaller groups and groups with less-constrained interaction structures (``thick channels'') showed stronger convergence to group-specific conventions than large groups with constrained interaction structures (``thin channels''), which struggled with convention formation. Overall, these results shed light on the core structural factors that enable communication to thrive in larger groups.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/UDFY7VSU/Boyce et al. - 2024 - Interaction structure constrains the emergence of conventions in group communication.pdf}
}

@article{branigan2006,
  title = {Perspectives on Multi-Party Dialogue},
  author = {Branigan, Holly},
  year = {2006},
  journal = {Research on Language and Computation},
  volume = {4},
  number = {2},
  pages = {153--177},
  publisher = {Springer},
  date-added = {2022-02-01 10:48:23 -0800},
  date-modified = {2022-02-01 10:48:28 -0800}
}

@article{branigan2016,
  title = {Do {{You Know What I Know}}? {{The Impact}} of {{Participant Role}} in {{Children}}'s {{Referential Communication}}},
  shorttitle = {Do {{You Know What I Know}}?},
  author = {Branigan, Holly P. and Bell, Jenny and McLean, Janet F.},
  year = {2016},
  month = feb,
  journal = {Frontiers in Psychology},
  volume = {7},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.00213},
  urldate = {2023-08-29},
  abstract = {For successful language use, interlocutors must be able to accurately assess their shared knowledge (``common ground''). Such knowledge can be accumulated through linguistic and non-linguistic context, but the same context can be associated with different patterns of knowledge, depending on the interlocutor's participant role (Wilkes-Gibbs and Clark, 1992). Although there is substantial evidence that children's ability to model partners' knowledge develops gradually, most such evidence focuses on non-linguistic context. We investigated the extent to which 8- to 10-year-old children can assess common ground developed through prior linguistic context, and whether this is sensitive to variations in participant role. Children repeatedly described tangram figures to another child, and then described the same figures to a third child who had been a side-participant, an overhearer, or absent during the initial conversation. Children showed evidence of partner modeling, producing shorter referential expressions with repeated mention to the same partner. Moreover, they demonstrated sensitivity to differences in common ground with the third child based on participant role on some but not all measures (e.g., description length, but not definiteness). Our results suggest that by ten, children make distinctions about common ground accumulated through prior linguistic context but do not yet consistently deploy this knowledge in an adult-like way.},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/EM9VXUUM/Branigan et al. - 2016 - Do You Know What I Know The Impact of Participant.pdf}
}

@article{brennan1996,
  ids = {brennanConceptualPactsLexicala},
  title = {Conceptual {{Pacts}} and {{Lexical Choice}} in {{Conversation}}},
  author = {Brennan, Susan E and Clark, Herbert H},
  year = {1996},
  pages = {12},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/3P7AEDCI/Brennan and Clark - Conceptual Pacts and Lexical Choice in Conversatio.pdf;/home/vboyce/Zotero/storage/A2533ATU/Brennan and Clark - Conceptual Pacts and Lexical Choice in Conversatio.pdf}
}

@article{brown-schmidt2012,
  title = {Beyond Common and Privileged: {{Gradient}} Representations of Common Ground in Real-Time Language Use},
  shorttitle = {Beyond Common and Privileged},
  author = {{Brown-Schmidt}, Sarah},
  year = {2012},
  month = jan,
  journal = {Language and Cognitive Processes},
  volume = {27},
  number = {1},
  pages = {62--89},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690965.2010.543363},
  urldate = {2023-10-20},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/Q6X7YGQC/Brown-Schmidt - 2012 - Beyond common and privileged Gradient representat.pdf}
}

@incollection{brown-schmidt2015,
  title = {People as {{Contexts}} in {{Conversation}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {{Brown-Schmidt}, Sarah and Yoon, Si On and Ryskin, Rachel Anna},
  year = {2015},
  volume = {62},
  pages = {59--99},
  publisher = {Elsevier},
  doi = {10.1016/bs.plm.2014.09.003},
  urldate = {2020-10-01},
  isbn = {978-0-12-802273-3},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/GFLWMIBE/Brown-Schmidt et al. - 2015 - People as Contexts in Conversation.pdf}
}

@inbook{brown-schmidt2018,
  title = {Perspective-{{Taking During Conversation}}},
  booktitle = {The {{Oxford Handbook}} of {{Psycholinguistics}}},
  author = {{Brown-Schmidt}, Sarah and Heller, Daphna},
  year = {2018},
  month = aug,
  pages = {548--572},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780198786825.013.23},
  urldate = {2023-08-31},
  abstract = {In conversation, each person has their own perspective which is shaped by their unique set of life experiences. Considering of how one's own perspective is similar to, or different from, the perspective of their conversational partner is crucial in order to communicate effectively in conversation. Effects of perspective are found in both production and comprehension, from the message level, to sentence type and structure, to words and their sounds. This chapter provides a review of past and present literature on the representations of perspective and the underlying mechanisms that support use of perspective in conversation, outlining both the central empirical findings and the key theoretical positions. We also discuss future lines of inquiry that would be essential to maintaining progress in our understanding of this most basic phenomenon.},
  collaborator = {{Brown-Schmidt}, Sarah and Heller, Daphna},
  isbn = {978-0-19-878682-5},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/G4NQBU6T/Brown-Schmidt and Heller - 2018 - Perspective-Taking During Conversation.pdf}
}

@article{burkner2018,
  title = {Advanced Bayesian Multilevel Modeling with the r Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  journal = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395--411},
  keywords = {read}
}

@article{bybee2006,
  title = {From {{Usage}} to {{Grammar}}: {{The Mind}}'s {{Response}} to {{Repetition}}},
  shorttitle = {From {{Usage}} to {{Grammar}}},
  author = {Bybee, Joan L.},
  year = {2006},
  journal = {Language},
  volume = {82},
  number = {4},
  pages = {711--733},
  issn = {1535-0665},
  doi = {10.1353/lan.2006.0186},
  urldate = {2023-06-14},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/87VA5NPY/Bybee - 2006 - From Usage to Grammar The Mind's Response to Repe.pdf}
}

@article{caplow1957,
  title = {Organizational Size},
  author = {Caplow, Theodore},
  year = {1957},
  journal = {Administrative Science Quarterly},
  pages = {484--505},
  publisher = {JSTOR}
}

@article{carletta1998,
  title = {Placement of {{Authority}} and {{Communication Patterns}} in {{Workplace Groups}}: {{The Consequences}} for {{Innovation}}},
  shorttitle = {Placement of {{Authority}} and {{Communication Patterns}} in {{Workplace Groups}}},
  author = {Carletta, Jean and Garrod, Simon and {Fraser-Krauss}, Heidi},
  year = {1998},
  month = oct,
  journal = {Small Group Research},
  volume = {29},
  number = {5},
  pages = {531--559},
  publisher = {SAGE Publications Inc},
  issn = {1046-4964},
  doi = {10.1177/1046496498295001},
  urldate = {2022-02-01},
  abstract = {Group discussion is typically made up of a series ofpairwise conversations. Using a corpus of workplace meetings in which decision-making authority is placed either in one individual or in the group as a whole, we demonstrate that both kinds of discussions are dominated by such conversations. However, in the groups with one authoritative individual, the same pairings recur, some people say more than others, and the authoritative individual dominates and controls the discussion, no matter how many people are present. In the groups that hold authority jointly, participation is more equal and more pairings are represented, but these properties degrade as discussion size increases. Current management theory about teams suggests that groups that have joint authority make better and more innovative decisions but that teams should be kept small. The theory of output/input coordination links these suggestions with the communication pattern differences observed.},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/I8WL2TIU/Carletta et al. - 1998 - Placement of Authority and Communication Patterns .pdf}
}

@article{carruthers2013,
  title = {Mindreading in {{Infancy}}},
  author = {Carruthers, Peter},
  year = {2013},
  month = apr,
  journal = {Mind \& Language},
  volume = {28},
  number = {2},
  pages = {141--172},
  issn = {0268-1064, 1468-0017},
  doi = {10.1111/mila.12014},
  urldate = {2025-01-16},
  abstract = {Various dichotomies have been proposed to characterize the nature and development of human mindreading capacities, especially in light of recent evidence of mindreading in infants aged 7 to 18 months. This article will examine these suggestions, arguing that none is currently supported by the evidence. Rather, the data support a modular account of the domain-specific component of basic mindreading capacities. This core component is present in infants from a very young age and does not alter fundamentally thereafter. What alters with development are the interactions between core mindreading and other systems, including executive systems, and forms of learning that do not require radical conceptual change.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/E8VVKMWY/Carruthers - 2013 - Mindreading in Infancy.pdf}
}

@book{cazden1988,
  title = {Classroom Discourse: {{The}} Language of Teaching and Learning.},
  author = {Cazden, Courtney B},
  year = {1988},
  publisher = {ERIC}
}

@inproceedings{chen2016,
  title = {Xgboost: {{A}} Scalable Tree Boosting System},
  booktitle = {Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  pages = {785--794}
}

@article{clark1986,
  title = {Referring as a Collaborative Process},
  author = {Clark, Herbert H and {Wilkes-Gibbs}, Deanna},
  year = {1986},
  urldate = {2020-10-06},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/88SILUKX/clark-and-wilkes-gibbs-1986.pdf}
}

@article{clark1987,
  title = {Concealing One's Meaning from Overhearers},
  author = {Clark, Herbert H and Schaefer, Edward F},
  year = {1987},
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {26},
  number = {2},
  pages = {209--225},
  issn = {0749596X},
  doi = {10.1016/0749-596X(87)90124-0},
  urldate = {2025-01-13},
  langid = {english},
  file = {/home/vboyce/Zotero/storage/8NGFJFFV/Clark and Schaefer - 1987 - Concealing one's meaning from overhearers.pdf}
}

@article{clark2004,
  title = {Speaking While Monitoring Addressees for Understanding},
  author = {Clark, Herbert H and Krych, Meredyth A},
  year = {2004},
  journal = {Journal of memory and language},
  volume = {50},
  number = {1},
  pages = {62--81},
  publisher = {Elsevier}
}

@article{cohn-gordon2018,
  title = {Pragmatically {{Informative Image Captioning}} with {{Character-Level Inference}}},
  author = {{Cohn-Gordon}, Reuben and Goodman, Noah and Potts, Christopher},
  year = {2018},
  month = may,
  journal = {arXiv:1804.05417 [cs]},
  eprint = {1804.05417},
  primaryclass = {cs},
  urldate = {2021-11-06},
  abstract = {We combine a neural image captioner with a Rational Speech Acts (RSA) model to make a system that is pragmatically informative: its objective is to produce captions that are not merely true but also distinguish their inputs from similar images. Previous attempts to combine RSA with neural image captioning require an inference which normalizes over the entire set of possible utterances. This poses a serious problem of efficiency, previously solved by sampling a small subset of possible utterances. We instead solve this problem by implementing a version of RSA which operates at the level of characters ("a","b","c"...) during the unrolling of the caption. We find that the utterance-level effect of referential captions can be obtained with only character-level decisions. Finally, we introduce an automatic method for testing the performance of pragmatic speaker models, and show that our model outperforms a non-pragmatic baseline as well as a word-level RSA captioner.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/IAD7Q4HM/Cohn-Gordon et al. - 2018 - Pragmatically Informative Image Captioning with Ch.pdf;/home/vboyce/Zotero/storage/H9RHMCTA/1804.html}
}

@article{cohn-gordon2018a,
  ids = {cohn-gordonIncrementalIteratedResponse2018a},
  title = {An {{Incremental Iterated Response Model}} of {{Pragmatics}}},
  author = {{Cohn-Gordon}, Reuben and Goodman, Noah D. and Potts, Christopher},
  year = {2018},
  month = oct,
  journal = {arXiv:1810.00367 [cs]},
  eprint = {1810.00367},
  primaryclass = {cs},
  urldate = {2020-05-04},
  abstract = {Recent Iterated Response (IR) models of pragmatics conceptualize language use as a recursive process in which agents reason about each other to increase communicative efficiency. These models are generally defined over complete utterances. However, there is substantial evidence that pragmatic reasoning takes place incrementally during production and comprehension. We address this with an incremental IR model. We compare the incremental and global versions using computational simulations, and we assess the incremental model against existing experimental data and in the TUNA corpus for referring expression generation, showing that the model can capture phenomena out of reach of global versions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/4SGKUNRI/Cohn-Gordon et al. - 2018 - An Incremental Iterated Response Model of Pragmati.pdf;/home/vboyce/Zotero/storage/4UQ5UXSY/Cohn-Gordon et al. - 2018 - An Incremental Iterated Response Model of Pragmati.pdf;/home/vboyce/Zotero/storage/5K3Q7VIC/1810.html;/home/vboyce/Zotero/storage/CZEWI9Z5/1810.html}
}

@unpublished{cohn-gordon2019,
  title = {The Pragmatics of Multiparty Communication},
  author = {{Cohn-Gordon}, Reuben and Levy, Roger and Bergen, Leon},
  year = {2019}
}

@article{colby2023,
  title = {Efficiency of Spoken Word Recognition Slows across the Adult Lifespan},
  author = {Colby, Sarah E. and McMurray, Bob},
  year = {2023},
  month = nov,
  journal = {Cognition},
  volume = {240},
  pages = {105588},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2023.105588},
  urldate = {2025-01-21},
  abstract = {Spoken word recognition is a critical hub during language processing, linking hearing and perception to meaning and syntax. Words must be recognized quickly and efficiently as speech unfolds to be successfully integrated into conversation. This makes word recognition a computationally challenging process even for young, normal hearing adults. Older adults often experience declines in hearing and cognition, which could be linked by age-related declines in the cognitive processes specific to word recognition. However, it is unclear whether changes in word recognition across the lifespan can be accounted for by hearing or domain-general cognition. Participants (N~=~107) responded to spoken words in a Visual World Paradigm task while their eyes were tracked to assess the real-time dynamics of word recognition. We examined several indices of word recognition from early adolescence through older adulthood (ages 11--78). The timing and proportion of eye fixations to target and competitor images reveals that spoken word recognition became more efficient through age 25 and began to slow in middle age, accompanied by declines in the ability to resolve competition (e.g., suppressing sandwich to recognize sandal). There was a unique effect of age even after accounting for differences in inhibitory control, processing speed, and hearing thresholds. This suggests a limited age range where listeners are peak performers.},
  keywords = {Aging,Lexical competition,read,Word recognition},
  file = {/home/vboyce/Zotero/storage/G488UYJB/Colby and McMurray - 2023 - Efficiency of spoken word recognition slows across the adult lifespan.pdf;/home/vboyce/Zotero/storage/WEGGHBPT/S0010027723002226.html}
}

@article{degen2020,
  title = {When Redundancy Is Useful: {{A Bayesian}} Approach to ``Overinformative'' Referring Expressions.},
  shorttitle = {When Redundancy Is Useful},
  author = {Degen, Judith and Hawkins, Robert D. and Graf, Caroline and Kreiss, Elisa and Goodman, Noah D.},
  year = {2020},
  journal = {Psychological Review},
  volume = {127},
  number = {4},
  pages = {591},
  publisher = {US: American Psychological Association},
  issn = {1939-1471},
  doi = {10.1037/rev0000186},
  urldate = {2023-06-14},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/Y5H7DXJR/Degen et al. - When redundancy is useful A Bayesian approach to .pdf}
}

@article{degen2021,
  title = {Seeing Is Believing: Testing an Explicit Linking Assumption for Visual World Eye-Tracking in Psycholinguistics},
  author = {Degen, Judith and Kursat, Leyla and Leigh, Daisy},
  year = {2021},
  journal = {CogSci},
  abstract = {Experimental investigation is fundamental to theory-building in cognitive science, but its value depends on the linking assumptions made by researchers about the mapping between empirical measurements and theoretical constructs. We argue that sufficient clarity and justification are often lacking for linking assumptions made in visual world eye-tracking, a widely used experimental method in psycholinguistic research. We test what we term the Referential Belief linking assumption: that the proportion of looks to a referent in a time window reflects participants' degree of belief that the referent is the intended target in that time window. We do so by comparing eye-tracking data against explicit beliefs collected in an incremental decision task (Exp. 1), which replicates a scalar implicature processing study (Exp. 3 of Sun \& Breheny, 2020). In Exp. 2, we replicate Sun and Breheny (2020) in a web-based eye-tracking paradigm using WebGazer.js. The results provide support for the Referential Belief link and cautious optimism for the prospect of conducting web-based eye-tracking. We discuss limitations on both fronts.},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/V4CN5K9Z/Degen et al. - Seeing is believing testing an explicit linking a.pdf}
}

@article{dewhirst1971,
  title = {Influence of Perceived Information-Sharing Norms on Communication Channel Utilization},
  author = {Dewhirst, H Dudley},
  year = {1971},
  journal = {Academy of Management Journal},
  volume = {14},
  number = {3},
  pages = {305--315},
  publisher = {Academy of Management Briarcliff Manor, NY 10510}
}

@article{eijk2022,
  title = {The {{CABB}} Dataset: {{A}} Multimodal Corpus of Communicative Interactions for Behavioural and Neural Analyses},
  shorttitle = {The {{CABB}} Dataset},
  author = {Eijk, Lotte and Rasenberg, Marlou and Arnese, Flavia and Blokpoel, Mark and Dingemanse, Mark and Doeller, Christian F. and Ernestus, Mirjam and Holler, Judith and Milivojevic, Branka and {\"O}zy{\"u}rek, Asli and Pouw, Wim and {van Rooij}, Iris and Schriefers, Herbert and Toni, Ivan and Trujillo, James and B{\"o}gels, Sara},
  year = {2022},
  month = dec,
  journal = {NeuroImage},
  volume = {264},
  pages = {119734},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2022.119734},
  urldate = {2024-07-22},
  abstract = {We present a dataset of behavioural and fMRI observations acquired in the context of humans involved in multimodal referential communication. The dataset contains audio/video and motion-tracking recordings of face-to-face, task-based communicative interactions in Dutch, as well as behavioural and neural correlates of participants' representations of dialogue referents. Seventy-one pairs of unacquainted participants performed two interleaved interactional tasks in which they described and located 16 novel geometrical objects (i.e., Fribbles) yielding spontaneous interactions of about one hour. We share high-quality video (from three cameras), audio (from head-mounted microphones), and motion-tracking (Kinect) data, as well as speech transcripts of the interactions. Before and after engaging in the face-to-face communicative interactions, participants' individual representations of the 16 Fribbles were estimated. Behaviourally, participants provided a written description (one to three words) for each Fribble and positioned them along 29 independent conceptual dimensions (e.g., rounded, human, audible). Neurally, fMRI signal evoked by each Fribble was measured during a one-back working-memory task. To enable functional hyperalignment across participants, the dataset also includes fMRI measurements obtained during visual presentation of eight animated movies (35~min total). We present analyses for the various types of data demonstrating their quality and consistency with earlier research. Besides high-resolution multimodal interactional data, this dataset includes different correlates of communicative referents, obtained before and after face-to-face dialogue, allowing for novel investigations into the relation between communicative behaviours and the representational space shared by communicators. This unique combination of data can be used for research in neuroscience, psychology, linguistics, and beyond.},
  keywords = {Conceptual alignment,Face-to-face interaction,fMRI,Motion tracking,Multimodal data,read,Referential communication},
  file = {/home/vboyce/Zotero/storage/RIHU89EW/Eijk et al. - 2022 - The CABB dataset A multimodal corpus of communica.pdf;/home/vboyce/Zotero/storage/BN3A88GG/S1053811922008552.html}
}

@misc{eliav2023,
  title = {Semantic Uncertainty Guides the Extension of Conventions to New Referents},
  author = {Eliav, Ron and Ji, Anya and Artzi, Yoav and Hawkins, Robert D.},
  year = {2023},
  month = may,
  number = {arXiv:2305.06539},
  eprint = {2305.06539},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.06539},
  urldate = {2023-06-13},
  abstract = {A long tradition of studies in psycholinguistics has examined the formation and generalization of ad hoc conventions in reference games, showing how newly acquired conventions for a given target transfer to new referential contexts. However, another axis of generalization remains understudied: how do conventions formed for one target transfer to completely distinct targets, when specific lexical choices are unlikely to repeat? This paper presents two dyadic studies (N = 240) that address this axis of generalization, focusing on the role of nameability -- the a priori likelihood that two individuals will share the same label. We leverage the recently-released KiloGram dataset, a collection of abstract tangram images that is orders of magnitude larger than previously available, exhibiting high diversity of properties like nameability. Our first study asks how nameability shapes convention formation, while the second asks how new conventions generalize to entirely new targets of reference. Our results raise new questions about how ad hoc conventions extend beyond target-specific re-use of specific lexical choices.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read,useful},
  file = {/home/vboyce/Zotero/storage/6XIKWS7K/Eliav et al. - 2023 - Semantic uncertainty guides the extension of conve.pdf}
}

@article{epley2004,
  title = {Perspective Taking in Children and Adults: {{Equivalent}} Egocentrism but Differential Correction},
  shorttitle = {Perspective Taking in Children and Adults},
  author = {Epley, Nicholas and Morewedge, Carey K and Keysar, Boaz},
  year = {2004},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {40},
  number = {6},
  pages = {760--768},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2004.02.002},
  urldate = {2025-01-07},
  abstract = {Children generally behave more egocentrically than adults when assessing another's perspective. We argue that this difference does not, however, indicate that adults process information less egocentrically than children, but rather that adults are better able to subsequently correct an initial egocentric interpretation. An experiment tracking participants' eye movements during a referential communication task indicated that children and adults were equally quick to interpret a spoken instruction egocentrically but differed in the speed with which they corrected that interpretation and looked at the intended (i.e., non-egocentric) object. The existing differences in egocentrism between children and adults therefore seems less a product of where people start in their perspective taking process than where they stop, with lingering egocentric biases among adults produced by insufficient correction of an automatic moment of egocentrism. We suggest that this pattern of similarity in automatic, but not controlled, processes may explain between-group differences in a variety of dual-process judgments.},
  keywords = {Automatic and controlled processes,Egocentric biases,Egocentrism,Judgmental correction,Perspective taking,read,Theory of mind},
  file = {/home/vboyce/Zotero/storage/H5LUKYTF/S0022103104000241.html}
}

@article{fay2000,
  title = {Group {{Discussion}} as {{Interactive Dialogue}} or as {{Serial Monologue}}: {{The Influence}} of {{Group Size}}},
  shorttitle = {Group {{Discussion}} as {{Interactive Dialogue}} or as {{Serial Monologue}}},
  author = {Fay, Nicolas and Garrod, Simon and Carletta, Jean},
  year = {2000},
  month = nov,
  journal = {Psychological Science},
  volume = {11},
  number = {6},
  pages = {481--486},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/1467-9280.00292},
  urldate = {2022-02-01},
  abstract = {Current models draw a broad distinction between communication as dialogue and communication as monologue. The two kinds of models have different implications for who influences whom in a group discussion. If the discussion is like interactive dialogue, group members should be influenced most by those with whom they interact in the discussion; if it is like serial monologue, they should be influenced most by the dominant speaker. The experiments reported here show that in small, 5-person groups, the communication is like dialogue and members are influenced most by those with whom they interact in the discussion. However, in large, 10-person groups, the communication is like monologue and members are influenced most by the dominant speaker. The difference in mode of communication is explained in terms of how speakers in the two sizes of groups design their utterances for different audiences.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/T73T254K/Fay et al. - 2000 - Group Discussion as Interactive Dialogue or as Ser.pdf;/home/vboyce/Zotero/storage/Y9VQ9VHA/Fay et al. - 2000 - Group Discussion as Interactive Dialogue or as Ser.pdf}
}

@article{fay2010,
  title = {The {{Interactive Evolution}} of {{Human Communication Systems}}},
  author = {Fay, Nicolas and Garrod, Simon and Roberts, Leo and Swoboda, Nik},
  year = {2010},
  journal = {Cognitive Science},
  volume = {34},
  number = {3},
  pages = {351--386},
  issn = {1551-6709},
  doi = {10.1111/j.1551-6709.2009.01090.x},
  urldate = {2020-12-02},
  abstract = {This paper compares two explanations of the process by which human communication systems evolve: iterated learning and social collaboration. It then reports an experiment testing the social collaboration account. Participants engaged in a graphical communication task either as a member of a community, where they interacted with seven different partners drawn from the same pool, or as a member of an isolated pair, where they interacted with the same partner across the same number of games. Participants' horizontal, pair-wise interactions led ``bottom up'' to the creation of an effective and efficient shared sign system in the community condition. Furthermore, the community-evolved sign systems were as effective and efficient as the local sign systems developed by isolated pairs. Finally, and as predicted by a social collaboration account, and not by an iterated learning account, interaction was critical to the creation of shared sign systems, with different isolated pairs establishing different local sign systems and different communities establishing different global sign systems.},
  langid = {english},
  keywords = {Graphical communication,Icon,Interaction,Iterated learning,Language evolution,read,Sign,Symbol},
  file = {/home/vboyce/Zotero/storage/XBFL4MSW/Fay et al. - 2010 - The Interactive Evolution of Human Communication S.pdf;/home/vboyce/Zotero/storage/8H4PR2GX/j.1551-6709.2009.01090.html}
}

@article{fernald2006,
  title = {Picking up Speed in Understanding: {{Speech}} Processing Efficiency and Vocabulary Growth across the 2nd Year},
  shorttitle = {Picking up Speed in Understanding},
  author = {Fernald, Anne and Perfors, Amy and Marchman, Virginia A.},
  year = {2006},
  month = jan,
  journal = {Developmental Psychology},
  volume = {42},
  number = {1},
  pages = {98--116},
  issn = {0012-1649},
  doi = {10.1037/0012-1649.42.1.98},
  abstract = {To explore how online speech processing efficiency relates to vocabulary growth in the 2nd year, the authors longitudinally observed 59 English-learning children at 15, 18, 21, and 25 months as they looked at pictures while listening to speech naming one of the pictures. The time course of eye movements in response to speech revealed significant increases in the efficiency of comprehension over this period. Further, speed and accuracy in spoken word recognition at 25 months were correlated with measures of lexical and grammatical development from 12 to 25 months. Analyses of growth curves showed that children who were faster and more accurate in online comprehension at 25 months were those who showed faster and more accelerated growth in expressive vocabulary across the 2nd year.},
  langid = {english},
  pmcid = {PMC3214591},
  pmid = {16420121},
  keywords = {Child Language,Child Preschool,Cognition,Female,Humans,Language Tests,Male,Reaction Time,read,Recognition Psychology,Speech Perception,Vocabulary},
  file = {/home/vboyce/Zotero/storage/SQ5K48TN/Fernald et al. - 2006 - Picking up speed in understanding Speech processing efficiency and vocabulary growth across the 2nd.pdf}
}

@article{ferreira2004,
  title = {Production-Comprehension Asymmetries},
  author = {Ferreira, Fernanda},
  year = {2004},
  month = apr,
  journal = {Behavioral and Brain Sciences},
  volume = {27},
  number = {2},
  pages = {196--196},
  publisher = {Cambridge University Press},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X04280050},
  urldate = {2024-02-01},
  abstract = {Pickering \& Garrod's (P\&G's) mechanistic theory of dialogue is a major advance for psycholinguistics. But the commitment to representational parity in production and comprehension is problematic. Recent research suggests that speakers frequently produce a structure that listeners find ungrammatical and have trouble understanding. If the grammars of the two systems are different, then the assumption of representational parity must be relaxed.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/VIXB3QLJ/Ferreira - 2004 - Production-comprehension asymmetries.pdf}
}

@article{foxtree2013,
  ids = {foxtreeCommunicativeEffectivenessWritten2013a},
  title = {Communicative {{Effectiveness}} of {{Written Versus Spoken Feedback}}},
  author = {Fox Tree, Jean E. and Clark, Nathaniel B.},
  year = {2013},
  month = jul,
  journal = {Discourse Processes},
  volume = {50},
  number = {5},
  pages = {339--359},
  publisher = {Routledge},
  issn = {0163-853X},
  doi = {10.1080/0163853X.2013.797241},
  urldate = {2022-02-01},
  abstract = {How does written and spoken feedback influence communicators' effectiveness in a shared task? Groups of two to four participants engaged in a referential communication task. The director described an array of shapes to the rest of the group via streaming video chat. In each group, one to three matchers attempted to arrange cards depicting those shapes into the director's arrangement. In one condition, matchers could speak to each other and the director through the video chat. In the other condition, matchers could only type contributions into a shared text chat. Spoken feedback dyads successfully arranged more cards than written feedback dyads. However, in groups with more than one matcher, feedback modalities were equally effective. Across group sizes and feedback types, when any matcher contributed more to the discourse, all matchers benefited. Spoken and written feedback groups differed in the amount and types of contributions matchers provided. Spoken feedback groups had more total discourse than written groups. Matchers in written groups made more bare requests for clarification, whereas matchers in spoken groups made more contributions of new information. These differences are explained in terms of constraints on grounding across the modalities.},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/DCPT54VD/Fox Tree and Clark - 2013 - Communicative Effectiveness of Written Versus Spok.pdf;/home/vboyce/Zotero/storage/29H4C7N2/0163853X.2013.html}
}

@article{frank2012a,
  ids = {frankPredictingPragmaticReasoning2012a},
  title = {Predicting {{Pragmatic Reasoning}} in {{Language Games}}},
  author = {Frank, M. C. and Goodman, N. D.},
  year = {2012},
  month = may,
  journal = {Science},
  volume = {336},
  number = {6084},
  pages = {998--998},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1218633},
  urldate = {2020-09-18},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/3GNASZFA/Frank and Goodman - 2012 - Predicting Pragmatic Reasoning in Language Games.pdf;/home/vboyce/Zotero/storage/WREI8FYU/Frank and Goodman - 2012 - Predicting Pragmatic Reasoning in Language Games.pdf}
}

@article{frank2014,
  title = {Inferring Word Meanings by Assuming That Speakers Are Informative},
  author = {Frank, Michael C. and Goodman, Noah D.},
  year = {2014},
  month = dec,
  journal = {Cognitive Psychology},
  volume = {75},
  pages = {80--96},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2014.08.002},
  urldate = {2020-09-24},
  abstract = {Language comprehension is more than a process of decoding the literal meaning of a speaker's utterance. Instead, by making the assumption that speakers choose their words to be informative in context, listeners routinely make pragmatic inferences that go beyond the linguistic data. If language learners make these same assumptions, they should be able to infer word meanings in otherwise ambiguous situations. We use probabilistic tools to formalize these kinds of informativeness inferences---extending a model of pragmatic language comprehension to the acquisition setting---and present four experiments whose data suggest that preschool children can use informativeness to infer word meanings and that adult judgments track quantitatively with informativeness.},
  langid = {english},
  keywords = {Bayesian models,Language acquisition,Pragmatics,read,Word learning},
  file = {/home/vboyce/Zotero/storage/SF3XR6Z4/Frank and Goodman - 2014 - Inferring word meanings by assuming that speakers .pdf;/home/vboyce/Zotero/storage/XCHLEZLK/S0010028514000589.html}
}

@techreport{frank2018,
  type = {Preprint},
  title = {Modeling Classroom Teaching as Optimal Communication},
  author = {Frank, Michael C. and Liu, Lawrence},
  year = {2018},
  month = dec,
  institution = {PsyArXiv},
  doi = {10.31234/osf.io/bucqx},
  urldate = {2020-09-15},
  abstract = {A good teacher is a good communicator. But communicating to a large audience can be difficult if audience members have differing preconceptions and hence construe the same message differently. Following this analogy of teaching as communication, we develop a framework for modeling classroom education as optimal communication to a variable audience. We study simple teaching games where teachers provide examples of a target concept to groups of students. Students synthesize these examples with their prior knowledge in order to induce the concept. We consider strategies for managing variability, including ability grouping ("tracking"), reductions in class size, and formative assessment. With known costs on actions, our model can also be extended for decision-theoretic analysis. This model provides a framework for estimating theoretical limits on the utility of educational interventions.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/N99FU2P2/Frank and Liu - 2018 - Modeling classroom teaching as optimal communicati.pdf}
}

@article{franke2016,
  title = {Reasoning in {{Reference Games}}: {{Individual-}} vs. {{Population-Level Probabilistic Modeling}}},
  shorttitle = {Reasoning in {{Reference Games}}},
  author = {Franke, Michael and Degen, Judith},
  editor = {Allen, Philip},
  year = {2016},
  month = may,
  journal = {PLOS ONE},
  volume = {11},
  number = {5},
  pages = {e0154854},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0154854},
  urldate = {2020-09-24},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/ZTXNQ8PN/Franke and Degen - 2016 - Reasoning in Reference Games Individual- vs. Popu.pdf}
}

@article{futrell2022,
  title = {Information {{Theory}} as a {{Bridge Between Language Function}} and {{Language Form}}},
  author = {Futrell, Richard and Hahn, Michael},
  year = {2022},
  journal = {Frontiers in Communication},
  volume = {7},
  issn = {2297-900X},
  urldate = {2023-06-13},
  abstract = {Formal and functional theories of language seem disparate, because formal theories answer the question of what a language is, while functional theories answer the question of what functions it serves. We argue that information theory provides a bridge between these two approaches, via a principle of minimization of complexity under constraints. Synthesizing recent work, we show how information-theoretic characterizations of functional complexity lead directly to mathematical descriptions of the forms of possible languages, in terms of solutions to constrained optimization problems. We show how certain linguistic descriptive formalisms can be recovered as solutions to such problems. Furthermore, we argue that information theory lets us define complexity in a way which has minimal dependence on the choice of theory or descriptive formalism. We illustrate this principle using recently-obtained results on universals of word and morpheme order.},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/PV2XX6K7/Futrell and Hahn - 2022 - Information Theory as a Bridge Between Language Fu.pdf}
}

@article{gandolfi2022,
  title = {Mechanisms of Alignment: Shared Control, Social Cognition and Metacognition},
  shorttitle = {Mechanisms of Alignment},
  author = {Gandolfi, Greta and Pickering, Martin J. and Garrod, Simon},
  year = {2022},
  month = dec,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {378},
  number = {1870},
  pages = {20210362},
  publisher = {Royal Society},
  doi = {10.1098/rstb.2021.0362},
  urldate = {2023-06-08},
  abstract = {In dialogue, speakers process a great deal of information, take and give the floor to each other, and plan and adjust their contributions on the fly. Despite the level of coordination and control that it requires, dialogue is the easiest way speakers possess to come to similar conceptualizations of the world. In this paper, we show how speakers align with each other by mutually controlling the flow of the dialogue and constantly monitoring their own and their interlocutors' way of representing information. Through examples of conversation, we introduce the notions of shared control, meta-representations of alignment and commentaries on alignment, and show how they support mutual understanding and the collaborative creation of abstract concepts. Indeed, whereas speakers can share similar representations of concrete concepts just by mutually attending to a tangible referent or by recalling it, they are likely to need more negotiation and mutual monitoring to build similar representations of abstract concepts. This article is part of the theme issue `Concepts in interaction: social engagement and inner experiences'.},
  keywords = {abstract concepts,alignment,dialogue,metacognition,read,shared control,social cognition},
  file = {/home/vboyce/Zotero/storage/E88U9GU5/Gandolfi et al. - 2022 - Mechanisms of alignment shared control, social co.pdf}
}

@misc{garrison2022,
  title = {Alcohol and {{Common Ground}}: {{The Effects}} of {{Intoxication}} on {{Linguistic Markers}} of {{Shared Understanding}} during {{Social Exchange}}},
  shorttitle = {Alcohol and {{Common Ground}}},
  author = {Garrison, Anna C. S. and Yoon, Si On and {Brown-Schmidt}, Sarah and Ariss, Talia and Fairbairn, Catharine},
  year = {2022},
  month = oct,
  publisher = {OSF Preprints},
  doi = {10.31219/osf.io/xrw6z},
  urldate = {2023-02-14},
  abstract = {Objective: Most alcohol consumption takes place in social contexts, and the belief that alcohol enhances social interactions has been identified as among the more robust predictors of alcohol use disorder (AUD) development. Yet we know little of how alcohol affects mental representations of others---what we share and do not share---nor the extent to which intoxication might impact the development of shared understanding (i.e., common ground) between interaction partners. Employing a randomized experimental design and objective linguistic outcome measures, we present two studies examining the impact of alcohol consumption on the development and use of common ground. Methods: In Study 1, groups of strangers or friends were administered either alcohol (target BAC=.08\%) or a control beverage, following which they completed a task requiring them to develop a shared language to describe ambiguous images and then describe those images to either a knowledgeable or a na{\"i}ve partner. The same procedures were completed in Study 2 using a within-subjects alcohol-administration design and all-stranger groups. Results: Study 1 findings did not reach significance but suggested that alcohol may facilitate common ground development selectively among stranger groups. This effect emerged as significant in the context of the within-subjects design of Study 2, b=-0.19, p=.007, with participants demonstrating greater facility in establishing common ground during Alcohol vs. Control sessions. Conclusion: Results suggest that alcohol facilitates the development of shared linguistic understanding in novel social spaces, indicating common ground as one potential mechanism to consider in our broader examination of alcohol reinforcement and AUD etiology.},
  archiveprefix = {OSF Preprints},
  langid = {american},
  keywords = {alcohol use,Clinical Psychology,common ground,Psychology,read,Social and Behavioral Sciences,social communication,social context,useful},
  file = {/home/vboyce/Zotero/storage/PST248QG/Garrison et al. - 2022 - Alcohol and Common Ground The Effects of Intoxica.pdf}
}

@article{garrod1994,
  title = {Conversation, Co-Ordination and Convention: An Empirical Investigation of How Groups Establish Linguistic Conventions},
  author = {Garrod, Simon and Doherty, Alice},
  year = {1994},
  pages = {12},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/8LZ6NDH5/garrod.pdf}
}

@article{garrod2007,
  title = {Foundations of {{Representation}}: {{Where Might Graphical Symbol Systems Come From}}?},
  shorttitle = {Foundations of {{Representation}}},
  author = {Garrod, Simon and Fay, Nicolas and Lee, John and Oberlander, Jon and MacLeod, Tracy},
  year = {2007},
  month = nov,
  journal = {Cognitive Science},
  volume = {31},
  number = {6},
  pages = {961--987},
  issn = {03640213},
  doi = {10.1080/03640210701703659},
  urldate = {2022-02-01},
  abstract = {It has been suggested that iconic graphical signs evolve into symbolic graphical signs through repeated usage. This article reports a series of interactive graphical communication experiments using a `pictionary' task to establish the conditions under which the evolution might occur. Experiment 1 rules out a simple repetition based account in favor of an account that requires feedback and interaction between communicators. Experiment 2 shows how the degree of interaction affects the evolution of signs according to a process of grounding. Experiment 3 confirms the prediction that those not involved directly in the interaction have trouble interpreting the graphical signs produced in Experiment 1. On the basis of these results, this article argues that icons evolve into symbols as a consequence of the systematic shift in the locus of information from the sign to the users' memory of the sign's usage supported by an interactive grounding process.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6AG3WBWH/Garrod et al. - 2007 - Foundations of Representation Where Might Graphic.pdf}
}

@article{garrod2009,
  title = {Joint {{Action}}, {{Interactive Alignment}}, and {{Dialog}}},
  author = {Garrod, Simon and Pickering, Martin J.},
  year = {2009},
  month = apr,
  journal = {Topics in Cognitive Science},
  volume = {1},
  number = {2},
  pages = {292--304},
  issn = {17568757, 17568765},
  doi = {10.1111/j.1756-8765.2009.01020.x},
  urldate = {2020-10-06},
  abstract = {Dialog is a joint action at different levels. At the highest level, the goal of interlocutors is to align their mental representations. This emerges from joint activity at lower levels, both concerned with linguistic decisions (e.g., choice of words) and nonlinguistic processes (e.g., alignment of posture or speech rate). Because of the high-level goal, the interlocutors are particularly concerned with close coupling at these lower levels. As we illustrate with examples, this means that imitation and entrainment are particularly pronounced during interactive communication. We then argue that the mechanisms underlying such processes involve covert imitation of interlocutors' communicative behavior, leading to emulation of their expected behavior. In other words, communication provides a very good example of predictive emulation, in a way that leads to successful joint activity.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/NXXM64GG/Garrod and Pickering - 2009 - Joint Action, Interactive Alignment, and Dialog.pdf}
}

@article{gates2020,
  title = {How to {{Be Helpful}} to {{Multiple People}} at {{Once}}},
  author = {Gates, Vael and Griffiths, Thomas L. and Dragan, Anca D.},
  year = {2020},
  journal = {Cognitive Science},
  volume = {44},
  number = {6},
  pages = {e12841},
  issn = {1551-6709},
  doi = {10.1111/cogs.12841},
  urldate = {2021-05-11},
  abstract = {When someone hosts a party, when governments choose an aid program, or when assistive robots decide what meal to serve to a family, decision-makers must determine how to help even when their recipients have very different preferences. Which combination of people's desires should a decision-maker serve? To provide a potential answer, we turned to psychology: What do people think is best when multiple people have different utilities over options? We developed a quantitative model of what people consider desirable behavior, characterizing participants' preferences by inferring which combination of ``metrics'' (maximax, maxsum, maximin, or inequality aversion [IA]) best explained participants' decisions in a drink-choosing task. We found that participants' behavior was best described by the maximin metric, describing the desire to maximize the happiness of the worst-off person, though participant behavior was also consistent with maximizing group utility (the maxsum metric) and the IA metric to a lesser extent. Participant behavior was consistent across variation in the agents involved and tended to become more maxsum-oriented when participants were told they were players in the task (Experiment 1). In later experiments, participants maintained maximin behavior across multi-step tasks rather than shortsightedly focusing on the individual steps therein (Experiment 2, Experiment 3). By repeatedly asking participants what choices they would hope for in an optimal, just decision-maker, and carefully disambiguating which quantitative metrics describe these nuanced choices, we help constrain the space of what behavior we desire in leaders, artificial intelligence systems helping decision-makers, and the assistive robots and decision-makers of the future.},
  langid = {english},
  keywords = {Assistive artificial intelligence,Fairness,Maximin,Modeling,Preferences,read},
  file = {/home/vboyce/Zotero/storage/GGHJX4JI/Gates et al. - 2020 - How to Be Helpful to Multiple People at Once.pdf;/home/vboyce/Zotero/storage/GIX2V7IU/cogs.html}
}

@article{gibson2019,
  title = {How {{Efficiency Shapes Human Language}}},
  author = {Gibson, Edward and Futrell, Richard and Piantadosi, Steven P. and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
  year = {2019},
  month = may,
  journal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {5},
  pages = {389--407},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.02.003},
  urldate = {2022-03-11},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/967VAUZL/Gibson et al. - 2019 - How Efficiency Shapes Human Language.pdf;/home/vboyce/Zotero/storage/QK458SEL/Gibson et al. - How Efficiency Shapes Human Language.pdf}
}

@article{ginzburg2005,
  title = {Action at a Distance: The Difference between Dialogue and Multilogue},
  author = {Ginzburg, Jonathan and Fernandez, Raquel},
  year = {2005},
  pages = {9},
  abstract = {The paper considers how to scale up dialogue protocols to multilogue, settings with multiple conversationalists. We extract two benchmarks to evaluate scaled up protocols based on the long distance resolution possibilities of nonsentential utterances in dialogue and multilogue in the British National Corpus. In light of these benchmarks, we then consider three possible transformations to dialogue protocols, inspired by Goffman's audience taxonomy and formulated within an issue-based approach to dialogue management. We show that one such transformation yields protocols for querying and assertion that fulfill these benchmarks. We indicate how these protocols can be implemented in terms of conversational update rules.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6ZVH8VLT/Ginzburg and Fernandez - Action at a distance the difference between dialo.pdf}
}

@misc{glucksberg1966,
  title = {Referential {{Communication}} in {{Nursery School Children}}: {{Method}} and {{Some Preliminary Findings}}},
  author = {Glucksberg, Sam and Krauss, Robert and Weisburg, Robert},
  year = {1966},
  urldate = {2022-06-08},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/I9FC9KB3/main.pdf}
}

@article{glucksberg1967,
  title = {{{WHAT DO PEOPLE SAY AFTER THEY HAVE LEARNED HOW TO TALK}}? {{STUDIES OF THE DEVELOPMENT OF REFERENTIAL COMMUNICATION}}},
  shorttitle = {{{WHAT DO PEOPLE SAY AFTER THEY HAVE LEARNED HOW TO TALK}}?},
  author = {Glucksberg, Sam and Krauss, Robert M.},
  year = {1967},
  journal = {Merrill-Palmer Quarterly of Behavior and Development},
  volume = {13},
  number = {4},
  eprint = {23082551},
  eprinttype = {jstor},
  pages = {309--316},
  publisher = {Wayne State University Press},
  issn = {0026-0150},
  urldate = {2022-06-06},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/K84T27ZA/Glucksberg and Krauss - 1967 - WHAT DO PEOPLE SAY AFTER THEY HAVE LEARNED HOW TO .pdf}
}

@article{goodman2013,
  ids = {goodmanKnowledgeImplicatureModeling2013a},
  title = {Knowledge and {{Implicature}}: {{Modeling Language Understanding}} as {{Social Cognition}}},
  shorttitle = {Knowledge and {{Implicature}}},
  author = {Goodman, Noah D. and Stuhlm{\"u}ller, Andreas},
  year = {2013},
  month = jan,
  journal = {Topics in Cognitive Science},
  volume = {5},
  number = {1},
  pages = {173--184},
  issn = {17568757},
  doi = {10.1111/tops.12007},
  urldate = {2020-09-24},
  abstract = {Is language understanding a special case of social cognition? To help evaluate this view, we can formalize it as the rational speech-act theory: Listeners assume that speakers choose their utterances approximately optimally, and listeners interpret an utterance by using Bayesian inference to ``invert'' this model of the speaker. We apply this framework to model scalar implicature (``some'' implies ``not all,'' and ``N'' implies ``not more than N''). This model predicts an interaction between the speaker's knowledge state and the listener's interpretation. We test these predictions in two experiments and find good fit between model predictions and human judgments.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/2G2Y8HT6/Goodman and Stuhlmüller - 2013 - Knowledge and Implicature Modeling Language Under.pdf;/home/vboyce/Zotero/storage/EJZUSUCR/Goodman and Stuhlmüller - 2013 - Knowledge and Implicature Modeling Language Under.pdf;/home/vboyce/Zotero/storage/FGSNNY4K/Goodman and Stuhlmüller - 2013 - Knowledge and Implicature Modeling Language Under.pdf}
}

@article{goodman2016,
  ids = {goodmanPragmaticLanguageInterpretation2016a},
  title = {Pragmatic {{Language Interpretation}} as {{Probabilistic Inference}}},
  author = {Goodman, Noah D. and Frank, Michael C.},
  year = {2016},
  month = nov,
  journal = {Trends in Cognitive Sciences},
  volume = {20},
  number = {11},
  pages = {818--829},
  issn = {13646613},
  doi = {10.1016/j.tics.2016.08.005},
  urldate = {2020-07-07},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/KT232S7M/Goodman and Frank - 2016 - Pragmatic Language Interpretation as Probabilistic.pdf;/home/vboyce/Zotero/storage/T9TMNR4D/Goodman and Frank - 2016 - Pragmatic Language Interpretation as Probabilistic.pdf}
}

@article{graham2014,
  title = {That's Not What You Said Earlier: Preschoolers Expect Partners to Be Referentially Consistent},
  shorttitle = {That's Not What You Said Earlier},
  author = {Graham, Susan A. and Sedivy, Julie and Khu, Melanie},
  year = {2014},
  month = jan,
  journal = {Journal of Child Language},
  volume = {41},
  number = {1},
  pages = {34--50},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000912000530},
  urldate = {2025-01-06},
  abstract = {In a conversation, adults expect speakers to be consistent in their use of a particular expression. We examine whether four-year-olds expect speakers to use consistent referential descriptions and whether these expectations are partner-specific. Using an eye-tracking paradigm, we presented four-year-olds with arrays of objects on a screen. During training, Experimenter 1 (E1) used a target expression to identify one object (i.e. ``the spotted dog'' to identify a dog that is both spotted and fluffy). Following training, either E1 or a new conversational partner (E2) presented children with test trials. Here, the target objects were referred to using either the original expression (e.g. ``the spotted dog'') or a new expression (e.g. ``the fluffy dog''). Eye-movements indicated that preschoolers were quicker to identify the target referent when the original expression was used by the same speaker. This suggests that four-year-olds, like adults, expect communicative partners to adhere to referential pacts.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/7UZ7YS7W/Graham et al. - 2014 - That's not what you said earlier preschoolers expect partners to be referentially consistent.pdf}
}

@article{grand2022,
  title = {Semantic Projection Recovers Rich Human Knowledge of Multiple Object Features from Word Embeddings},
  author = {Grand, Gabriel and Blank, Idan Asher and Pereira, Francisco and Fedorenko, Evelina},
  year = {2022},
  month = jul,
  journal = {Nature human behaviour},
  volume = {6},
  number = {7},
  pages = {975--987},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01316-8},
  urldate = {2025-01-13},
  abstract = {How is knowledge about word meaning represented in the mental lexicon? Current computational models infer word meanings from lexical co-occurrence patterns. They learn to represent words as vectors in a multidimensional space, wherein words that are used in more similar linguistic contexts---that is, are more semantically related---are located closer together. However, whereas inter-word proximity captures only overall relatedness, human judgements are highly context dependent. For example, dolphins and alligators are similar in size but differ in dangerousness. Here, we use a domain-general method to extract context-dependent relationships from word embeddings: `semantic projection' of word-vectors onto lines that represent features such as size (the line connecting the words `small' and `big') or danger (`safe' to `dangerous'), analogous to `mental scales'. This method recovers human judgements across various object categories and properties. Thus, the geometry of word embeddings explicitly represents a wealth of context-dependent world knowledge.},
  pmcid = {PMC10349641},
  pmid = {35422527},
  file = {/home/vboyce/Zotero/storage/P9DUSTHN/Grand et al. - 2022 - Semantic projection recovers rich human knowledge of multiple object features from word embeddings.pdf}
}

@misc{griffiths2023,
  title = {Bayes in the Age of Intelligent Machines},
  author = {Griffiths, Thomas L. and Zhu, Jian-Qiao and Grant, Erin and McCoy, R. Thomas},
  year = {2023},
  month = nov,
  number = {arXiv:2311.10206},
  eprint = {2311.10206},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-11-23},
  abstract = {The success of methods based on artificial neural networks in creating intelligent machines seems like it might pose a challenge to explanations of human cognition in terms of Bayesian inference. We argue that this is not the case, and that in fact these systems offer new opportunities for Bayesian modeling. Specifically, we argue that Bayesian models of cognition and artificial neural networks lie at different levels of analysis and are complementary modeling approaches, together offering a way to understand human cognition that spans these levels. We also argue that the same perspective can be applied to intelligent machines, where a Bayesian approach may be uniquely valuable in understanding the behavior of large, opaque artificial neural networks that are trained on proprietary data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,read},
  file = {/home/vboyce/Zotero/storage/KTU6HT4G/Griffiths et al. - 2023 - Bayes in the age of intelligent machines.pdf}
}

@article{grigoroglou2019,
  title = {Interactive Contexts Increase Informativeness in Children's Referential Communication.},
  author = {Grigoroglou, Myrto and Papafragou, Anna},
  year = {2019},
  month = may,
  journal = {Developmental Psychology},
  volume = {55},
  number = {5},
  pages = {951--966},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/dev0000693},
  urldate = {2025-01-06},
  abstract = {Adults adjust the informativeness of their utterances to the needs of their addressee. For children, however, relevant evidence is mixed. In this article we explore the communicative circumstances under which children offer informative descriptions. In Experiment 1, 4- and 5-year-old children and adults described a target event from a pair of almost identical events to a passive confederate listener who could either see or not see the referents. Adults provided disambiguating information that picked out the target event but children massively failed to do so (even though 5-year-olds were more informative than 4-year-olds). Furthermore, both children and adults were more likely to mention atypical than typical disambiguating event components. Because of the contrastive nature of the task, the listener's visual access had no effects on production. Experiment 2 was a more interactive version of Experiment 1 where participants played a guessing game with a ``na{\"i}ve'' listener. In this context, children (and adults) became overall more informative, and the difference between child groups disappeared. We conclude that the informativeness of children's event descriptions is heavily context-dependent and is boosted when children engage in a collaborative interaction with a ``true'' interlocutor.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/EL44CNWC/Grigoroglou and Papafragou - 2019 - Interactive contexts increase informativeness in children’s referential communication..pdf}
}

@article{guilbeault2021,
  title = {Experimental Evidence for Scale-Induced Category Convergence across Populations},
  author = {Guilbeault, Douglas and Baronchelli, Andrea and Centola, Damon},
  year = {2021},
  month = jan,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {327},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-20037-y},
  urldate = {2022-04-20},
  abstract = {Individuals vary widely in how they categorize novel and ambiguous phenomena. This individual variation has led influential theories in cognitive and social science to suggest that communication in large social groups introduces path dependence in category formation, which is expected to lead separate populations toward divergent cultural trajectories. Yet, anthropological data indicates that large, independent societies consistently arrive at highly similar category systems across a range of topics. How is it possible for diverse populations, consisting of individuals with significant variation in how they categorize the world, to independently construct similar category systems? Here, we investigate this puzzle experimentally by creating an online ``Grouping Game'' in which we observe how people in small and large populations collaboratively construct category systems for a continuum of ambiguous stimuli. We find that solitary individuals and small groups produce highly divergent category systems; however, across independent trials with unique participants, large populations consistently converge on highly similar category systems. A formal model of critical mass dynamics in social networks accurately predicts this process of scale-induced category convergence. Our findings show how large communication networks can filter lexical diversity among individuals to produce replicable society-level patterns, yielding unexpected implications for cultural evolution.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Evolution of language,read,Sociology,useful},
  file = {/home/vboyce/Zotero/storage/AAXFI34U/Guilbeault et al. - 2021 - Experimental evidence for scale-induced category c.pdf;/home/vboyce/Zotero/storage/B7I2SDRF/Guilbeault et al. - 2021 - Experimental evidence for scale-induced category c.pdf;/home/vboyce/Zotero/storage/K4F5PU4H/s41467-020-20037-y.html}
}

@misc{gul2024,
  title = {{{CoGen}}: {{Learning}} from {{Feedback}} with {{Coupled Comprehension}} and {{Generation}}},
  shorttitle = {{{CoGen}}},
  author = {Gul, Mustafa Omer and Artzi, Yoav},
  year = {2024},
  month = aug,
  number = {arXiv:2408.15992},
  eprint = {2408.15992},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.15992},
  urldate = {2024-12-03},
  abstract = {Systems with both language comprehension and generation capabilities can benefit from the tight connection between the two. This work studies coupling comprehension and generation with focus on continually learning from interaction with users. We propose techniques to tightly integrate the two capabilities for both learning and inference. We situate our studies in two-player reference games, and deploy various models for thousands of interactions with human users, while learning from interaction feedback signals. We show dramatic improvements in performance over time, with comprehension-generation coupling leading to performance improvements up to 26\% in absolute terms and up to 17\% higher accuracies compared to a non-coupled system. Our analysis also shows coupling has substantial qualitative impact on the system's language, making it significantly more human-like.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,read,useful},
  file = {/home/vboyce/Zotero/storage/FGZSKHYE/Gul and Artzi - 2024 - CoGen Learning from Feedback with Coupled Comprehension and Generation.pdf;/home/vboyce/Zotero/storage/YQDKB8KS/2408.html}
}

@article{gwilliams2022,
  title = {Top-down Information Flow Drives Lexical Access When Listening to Continuous Speech},
  author = {Gwilliams, Laura and Marantz, Alec and Poeppel, David and King, Jean-Remi},
  year = {2022},
  journal = {bioRxiv},
  abstract = {Speech is noisy, ambiguous and complex. Here we study how the human brain uses high-order linguistic structure to guide comprehension. Twenty-one participants listened to spoken narratives while magneto-encephalography (MEG) was recorded. Stories were annotated for word class (specifically: noun, verb, adjective) under two hypothesised sources of information: (i) `bottom-up': the most common word class given by the word's phonology; (ii) `top-down': the true word class given the syntactic context. We trained a classifier on trials where the two hypotheses matched (about 90\%), and tested the classifier on trials where they mismatched. The classifier predicted only the syntactic word class labels, in line with the top-down hypothesis. These effects peaked {$\sim$}400ms after word offset over frontal MEG sensors. Our results support that when processing continuous speech, lexical representations are quickly built in a context-sensitive manner. We showcase the utility of multivariate analyses in teasing apart subtle representational distinctions from neural time series.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/KEMTUYKN/Gwilliams et al. - Top-down information flow drives lexical access wh.pdf}
}

@inproceedings{haber2019,
  title = {The {{PhotoBook Dataset}}: {{Building Common Ground}} through {{Visually-Grounded Dialogue}}},
  shorttitle = {The {{PhotoBook Dataset}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Haber, Janosch and Baumg{\"a}rtner, Tim and Takmaz, Ece and Gelderloos, Lieke and Bruni, Elia and Fern{\'a}ndez, Raquel},
  year = {2019},
  pages = {1895--1910},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/P19-1184},
  urldate = {2022-02-01},
  langid = {english},
  keywords = {read}
}

@article{hanna2003,
  title = {The Effects of Common Ground and Perspective on Domains of Referential Interpretation},
  author = {Hanna, Joy E and Tanenhaus, Michael K and Trueswell, John C},
  year = {2003},
  month = jul,
  journal = {Journal of Memory and Language},
  volume = {49},
  number = {1},
  pages = {43--61},
  issn = {0749-596X},
  doi = {10.1016/S0749-596X(03)00022-6},
  urldate = {2023-04-05},
  abstract = {Addressees' eye movements were tracked as they followed instructions given by a confederate speaker hidden from view. Experiment 1 used objects in common ground (known to both participants) or privileged ground (known to the addressee). Although privileged objects interfered with reference to an identical object in common ground, addressees were always more likely to look at an object in common ground than privileged ground. Experiment 2 used definite and indefinite referring expressions with early or late points of disambiguation, depending on the uniqueness of the display objects. The speaker's and addressee's perspectives matched when the speaker was accurately informed about the display, and mismatched when the speaker was misinformed. When perspectives matched, addressees identified the target faster with early than with late disambiguation displays. When perspectives mismatched, addressees still identified the target quickly, showing an ability to use the speaker's perspective. These experiments demonstrate that although addressees cannot completely ignore information in privileged ground, common ground and perspective each have immediate effects on reference resolution.},
  langid = {english},
  keywords = {Common ground,Communication,Conversation,Language,Perspective,read,Reference resolution},
  file = {/home/vboyce/Zotero/storage/XKPH8QV6/Hanna et al. - 2003 - The effects of common ground and perspective on do.pdf;/home/vboyce/Zotero/storage/QGFU7UU3/S0749596X03000226.html}
}

@misc{hawkins1995,
  title = {A {{Performance Theory}} of {{Order}} and {{Constituency}}},
  author = {Hawkins, John},
  year = {1995},
  publisher = {Cambridge University Press},
  keywords = {read}
}

@article{hawkins2015,
  title = {Conducting Real-Time Multiplayer Experiments on the Web},
  author = {Hawkins, Robert X. D.},
  year = {2015},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {47},
  number = {4},
  pages = {966--976},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0515-6},
  urldate = {2020-11-30},
  abstract = {Group behavior experiments require potentially large numbers of participants to interact in real time with perfect information about one another. In this paper, we address the methodological challenge of developing and conducting such experiments on the web, thereby broadening access to online labor markets as well as allowing for participation through mobile devices. In particular, we combine a set of recent web development technologies, including Node.js with the Socket.io module, HTML5 canvas, and jQuery, to provide a secure platform for pedagogical demonstrations and scalable, unsupervised experiment administration. Template code is provided for an example real-time behavioral game theory experiment which automatically pairs participants into dyads and places them into a virtual world. In total, this treatment is intended to allow those with a background in non-web-based programming to modify the template, which handles the technical server--client networking details, for their own experiments.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/2W8JPFGB/Hawkins - 2015 - Conducting real-time multiplayer experiments on th.pdf}
}

@article{hawkins2019,
  title = {The {{Emergence}} of {{Social Norms}} and {{Conventions}}},
  author = {Hawkins, Robert X.D. and Goodman, Noah D. and Goldstone, Robert L.},
  year = {2019},
  month = feb,
  journal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {2},
  pages = {158--169},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.11.003},
  urldate = {2020-05-04},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/5M8R3UV3/Hawkins et al. - 2019 - The Emergence of Social Norms and Conventions.pdf;/home/vboyce/Zotero/storage/LR9NZGQV/Hawkins et al. - 2019 - The Emergence of Social Norms and Conventions.pdf}
}

@article{hawkins2020,
  title = {Characterizing the Dynamics of Learning in Repeated Reference Games},
  author = {Hawkins, Robert D. and Frank, Michael C. and Goodman, Noah D.},
  year = {2020},
  month = apr,
  journal = {arXiv:1912.07199 [cs]},
  eprint = {1912.07199},
  primaryclass = {cs},
  urldate = {2020-07-15},
  abstract = {The language we use over the course of conversation changes as we establish common ground and learn what our partner finds meaningful. Here we draw upon recent advances in natural language processing to provide a finer-grained characterization of the dynamics of this learning process. We release an open corpus ({$>$}15,000 utterances) of extended dyadic interactions in a classic repeated reference game task where pairs of participants had to coordinate on how to refer to initially difficult-to-describe tangram stimuli. We find that different pairs discover a wide variety of idiosyncratic but efficient and stable solutions to the problem of reference. Furthermore, these conventions are shaped by the communicative context: words that are more discriminative in the initial context (i.e. that are used for one target more than others) are more likely to persist through the final repetition. Finally, we find systematic structure in how a speaker's referring expressions become more efficient over time: syntactic units drop out in clusters following positive feedback from the listener, eventually leaving short labels containing open-class parts of speech. These findings provide a higher resolution look at the quantitative dynamics of ad hoc convention formation and support further development of computational models of learning in communication.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/5BIBRUG4/Hawkins et al. - 2020 - Characterizing the Dynamics of Learning in Repeate.pdf;/home/vboyce/Zotero/storage/AQTF8QH5/1912.html}
}

@article{hawkins2020a,
  ids = {hawkinsGeneralizingMeaningsPartners2020a},
  title = {Generalizing Meanings from Partners to Populations: {{Hierarchical}} Inference Supports Convention Formation on Networks},
  shorttitle = {Generalizing Meanings from Partners to Populations},
  author = {Hawkins, Robert D. and Goodman, Noah D. and Goldberg, Adele E. and Griffiths, Thomas L.},
  year = {2020},
  journal = {arXiv:2002.01510 [cs]},
  eprint = {2002.01510},
  primaryclass = {cs},
  urldate = {2020-10-01},
  abstract = {A key property of linguistic conventions is that they hold over an entire community of speakers, allowing us to communicate efficiently even with people we have never met before. At the same time, much of our language use is partner-specific: we know that words may be understood differently by different people based on our shared history. This poses a challenge for accounts of convention formation. Exactly how do agents make the inferential leap to community-wide expectations while maintaining partner-specific knowledge? We propose a hierarchical Bayesian model to explain how speakers and listeners solve this inductive problem. To evaluate our model's predictions, we conducted an experiment where participants played an extended natural-language communication game with different partners in a small community. We examine several measures of generalization and find key signatures of both partner-specificity and community convergence that distinguish our model from alternatives. These results suggest that partner-specificity is not only compatible with the formation of community-wide conventions, but may facilitate it when coupled with a powerful inductive mechanism.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Social and Information Networks,read},
  file = {/home/vboyce/Zotero/storage/2CMCH58R/Hawkins et al. - 2020 - Generalizing meanings from partners to populations.pdf;/home/vboyce/Zotero/storage/H6PSRZ7M/Hawkins et al. - 2020 - Generalizing meanings from partners to populations.pdf;/home/vboyce/Zotero/storage/M8AVSFVJ/2002.html;/home/vboyce/Zotero/storage/Y3MZZJ3Q/2002.html}
}

@article{hawkins2020,
  ids = {hawkinsContinualAdaptationEfficient2020a},
  title = {Continual Adaptation for Efficient Machine Communication},
  author = {Hawkins, Robert D. and Kwon, Minae and Sadigh, Dorsa and Goodman, Noah D.},
  year = {2020},
  month = oct,
  journal = {arXiv:1911.09896 [cs]},
  eprint = {1911.09896},
  primaryclass = {cs},
  urldate = {2020-12-02},
  abstract = {To communicate with new partners in new contexts, humans rapidly form new linguistic conventions. Recent neural language models are able to comprehend and produce the existing conventions present in their training data, but are not able to flexibly and interactively adapt those conventions on the fly as humans do. We introduce an interactive repeated reference task as a benchmark for models of adaptation in communication and propose a regularized continual learning framework that allows an artificial agent initialized with a generic language model to more accurately and efficiently communicate with a partner over time. We evaluate this framework through simulations on COCO and in real-time reference game experiments with human partners.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/23R4CG2X/Hawkins et al. - 2020 - Continual adaptation for efficient machine communi.pdf}
}

@misc{hawkins2021,
  title = {From Partners to Populations: {{A}} Hierarchical {{Bayesian}} Account of Coordination and Convention},
  shorttitle = {From Partners to Populations},
  author = {Hawkins, Robert D. and Franke, Michael and Frank, Michael C. and Goldberg, Adele E. and Smith, Kenny and Griffiths, Thomas L. and Goodman, Noah D.},
  year = {2021},
  month = dec,
  number = {arXiv:2104.05857},
  eprint = {2104.05857},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2104.05857},
  urldate = {2022-11-09},
  abstract = {Languages are powerful solutions to coordination problems: they provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. Yet language use in a variable and non-stationary social environment requires linguistic representations to be flexible: old words acquire new ad hoc or partner-specific meanings on the fly. In this paper, we introduce CHAI (Continual Hierarchical Adaptation through Inference), a hierarchical Bayesian theory of coordination and convention formation that aims to reconcile the long-standing tension between these two basic observations. We argue that the central computational problem of communication is not simply transmission, as in classical formulations, but continual learning and adaptation over multiple timescales. Partner-specific common ground quickly emerges from social inferences within dyadic interactions, while community-wide social conventions are stable priors that have been abstracted away from interactions with multiple partners. We present new empirical data alongside simulations showing how our model provides a computational foundation for several phenomena that have posed a challenge for previous accounts: (1) the convergence to more efficient referring expressions across repeated interaction with the same partner, (2) the gradual transfer of partner-specific common ground to strangers, and (3) the influence of communicative context on which conventions eventually form.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,read,useful},
  file = {/home/vboyce/Zotero/storage/SFP5KKDY/Hawkins et al. - 2021 - From partners to populations A hierarchical Bayes.pdf}
}

@article{hawkins2021a,
  ids = {hawkinsRespectCodeSpeakersa},
  title = {Respect the Code: {{Speakers}} Expect Novel Conventions to Generalize within but Not across Social Group Boundaries},
  author = {Hawkins, Robert D and Liu, Irina and Goldberg, Adele E and Griffiths, Thomas G},
  year = {2021},
  journal = {CogSci},
  abstract = {Speakers use different language to communicate with partners in different communities. But how do we learn and represent which conventions to use with which partners? In this paper, we argue that solving this challenging computational problem requires speakers to supplement their lexical representations with knowledge of social group structure. We formalize this idea by extending a recent hierarchical Bayesian model of convention formation with an intermediate layer explicitly representing the latent communities each partner belongs to, and derive predictions about how conventions formed within a group ought to extend to new in-group and out-group members. We then present evidence from two behavioral experiments testing these predictions using a minimal group paradigm. Taken together, our findings provide a first step toward a formal framework for understanding the interplay between language use and social group knowledge.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/CPX5SA7V/Hawkins et al. - Respect the code Speakers expect novel convention.pdf;/home/vboyce/Zotero/storage/EXDEHXYG/Hawkins et al. - Respect the code Speakers expect novel convention.pdf}
}

@article{hawkins2023,
  title = {Visual Resemblance and Interaction History Jointly Constrain Pictorial Meaning},
  author = {Hawkins, Robert D and Sano, Megumi and Goodman, Noah D and Fan, Judith E},
  year = {2023},
  langid = {english},
  keywords = {Human behaviour,read,Social behaviour,useful},
  file = {/home/vboyce/Zotero/storage/6IZJTYGQ/Hawkins et al. - Visual resemblance and interaction history jointly.pdf;/home/vboyce/Zotero/storage/DGDAIPLK/Hawkins et al. - 2023 - Visual resemblance and interaction history jointly constrain pictorial meaning.pdf}
}

@article{hawkins2023a,
  title = {From Partners to Populations: {{A}} Hierarchical {{Bayesian}} Account of Coordination and Convention.},
  author = {Hawkins, Robert D and Franke, Michael and Frank, Michael C and Goldberg, Adele E and Smith, Kenny and Griffiths, Thomas L and Goodman, Noah D},
  year = {2023},
  journal = {Psychological Review},
  volume = {130},
  number = {4},
  pages = {977},
  publisher = {American Psychological Association}
}

@article{hawkinsa,
  title = {Disentangling Contributions of Visual Information and Interaction History in the Formation of Graphical Conventions},
  author = {Hawkins, Robert X D and Sano, Megumi and Goodman, Noah D and Fan, Judith E},
  abstract = {Drawing is a versatile technique for visual communication, ranging from photorealistic renderings to schematic diagrams consisting entirely of symbols. How does a medium spanning such a broad range of appearances reliably convey meaning? A natural possibility is that drawings derive meaning from both their visual properties as well as shared knowledge between people who use them to communicate. Here we evaluate this possibility in a drawing-based reference game in which two participants repeatedly communicated about visual objects. Across a series of controlled experiments, we found that pairs of participants discover increasingly sparse yet effective ways of depicting objects. These gains were specific to those objects that were repeatedly referenced, and went beyond what could be explained by task practice or the visual properties of the drawings alone. We employed modern techniques from computer vision to characterize how the high-level visual features of drawings changed, finding that drawings of the same object became more consistent within a pair of participants and divergent across participants from different interactions. Taken together, these findings suggest that visual communication promotes the emergence of depictions whose meanings are increasingly determined by shared knowledge rather than their visual properties alone.},
  langid = {english},
  keywords = {drawing-tangrams,read,useful},
  file = {/home/vboyce/Zotero/storage/UPPBSXD7/Hawkins et al. - Disentangling contributions of visual information .pdf}
}

@article{hawkinsc,
  title = {Convention-Formation in Iterated Reference Games},
  author = {Hawkins, Robert X D and Frank, Michael C and Goodman, Noah D},
  pages = {6},
  abstract = {What cognitive mechanisms support the emergence of linguistic conventions from repeated interaction? We present results from a large-scale, multi-player replication of the classic tangrams task, focusing on three foundational properties of conventions: arbitrariness, stability, and reduction of utterance length over time. These results motivate a theory of convention-formation where agents, though initially uncertain about word meanings in context, assume others are using language with such knowledge. Thus, agents may learn about meanings by reasoning about a knowledgeable, informative partner; if all agents engage in such a process, they successfully coordinate their beliefs, giving rise to a conventional communication system. We formalize this theory in a computational model of language understanding as social inference and demonstrate that it produces all three properties in a simplified domain.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/WXIDZRLI/Hawkins et al. - Convention-formation in iterated reference games.pdf}
}

@article{healey2018,
  title = {Running {{Repairs}}: {{Coordinating Meaning}} in {{Dialogue}}},
  shorttitle = {Running {{Repairs}}},
  author = {Healey, Patrick G. T. and Mills, Gregory J. and Eshghi, Arash and Howes, Christine},
  year = {2018},
  journal = {Topics in Cognitive Science},
  volume = {10},
  number = {2},
  pages = {367--388},
  issn = {1756-8765},
  doi = {10.1111/tops.12336},
  urldate = {2022-02-01},
  abstract = {People give feedback in conversation: both positive signals of understanding, such as nods, and negative signals of misunderstanding, such as frowns. How do signals of understanding and misunderstanding affect the coordination of language use in conversation? Using a chat tool and a maze-based reference task, we test two experimental manipulations that selectively interfere with feedback in live conversation: (a) ``Attenuation'' that replaces positive signals of understanding such as ``right'' or ``okay'' with weaker, more provisional signals such as ``errr'' or ``umm'' and (2) ``Amplification'' that replaces relatively specific signals of misunderstanding from clarification requests such as ``on the left?'' with generic signals of trouble such as ``huh?'' or ``eh?''. The results show that Amplification promotes rapid convergence on more systematic, abstract ways of describing maze locations while Attenuation has no significant effect. We interpret this as evidence that ``running repairs''---the processes of dealing with misunderstandings on the fly---are key drivers of semantic coordination in dialogue. This suggests a new direction for experimental work on conversation and a productive way to connect the empirical accounts of Conversation Analysis with the representational and processing concerns of Formal Semantics and Psycholinguistics.},
  langid = {english},
  keywords = {Dialogue,Miscommunication,read,Repair},
  file = {/home/vboyce/Zotero/storage/QFQVNEEN/Healey et al. - 2018 - Running Repairs Coordinating Meaning in Dialogue.pdf;/home/vboyce/Zotero/storage/4UVAJRS5/tops.html}
}

@article{heller2012,
  title = {To {{Name}} or to {{Describe}}: {{Shared Knowledge Affects Referential Form}}},
  shorttitle = {To {{Name}} or to {{Describe}}},
  author = {Heller, Daphna and Gorman, Kristen S. and Tanenhaus, Michael K.},
  year = {2012},
  journal = {Topics in Cognitive Science},
  volume = {4},
  number = {2},
  pages = {290--305},
  issn = {1756-8765},
  doi = {10.1111/j.1756-8765.2012.01182.x},
  urldate = {2023-06-14},
  abstract = {The notion of common ground is important for the production of referring expressions: In order for a referring expression to be felicitous, it has to be based on shared information. But determining what information is shared and what information is privileged may require gathering information from multiple sources, and constantly coordinating and updating them, which might be computationally too intensive to affect the earliest moments of production. Previous work has found that speakers produce overinformative referring expressions, which include privileged names, violating Grice's Maxims, and concluded that this is because they do not mark the distinction between shared and privileged information. We demonstrate that speakers are in fact quite effective in marking this distinction in the form of their utterances. Nonetheless, under certain circumstances, speakers choose to overspecify privileged names.},
  copyright = {Copyright {\copyright} 2012 Cognitive Science Society, Inc.},
  langid = {english},
  keywords = {Common ground,Language production,Names,Perspective taking,read,Referring expressions,useful},
  file = {/home/vboyce/Zotero/storage/9V7RPJJ3/Heller et al. - 2012 - To Name or to Describe Shared Knowledge Affects R.pdf}
}

@article{hiltz1986,
  title = {Experiments in Group Decision Making: {{Communication}} Process and Outcome in Face-to-Face versus Computerized Conferences},
  author = {Hiltz, Starr Roxanne and Johnson, Kenneth and Turoff, Murray},
  year = {1986},
  journal = {Human communication research},
  volume = {13},
  number = {2},
  pages = {225--252},
  publisher = {Wiley Online Library}
}

@article{hockett1960,
  title = {The {{Origin}} of {{Speech}}},
  author = {Hockett, Charles F. and Hockett, Charles D.},
  year = {1960},
  journal = {Scientific American},
  volume = {203},
  number = {3},
  eprint = {24940617},
  eprinttype = {jstor},
  pages = {88--97},
  publisher = {Scientific American, a division of Nature America, Inc.},
  issn = {0036-8733},
  urldate = {2023-06-14},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/2DB34K3Y/Hockett and Hockett - 1960 - The Origin of Speech.pdf}
}

@article{horton1996,
  title = {When Do Speakers Take into Account Common Ground?},
  author = {Horton, William S. and Keysar, Boaz},
  year = {1996},
  month = apr,
  journal = {Cognition},
  volume = {59},
  number = {1},
  pages = {91--117},
  issn = {0010-0277},
  doi = {10.1016/0010-0277(96)81418-1},
  urldate = {2023-06-14},
  abstract = {What role does common ground play in the production of utterances? We outline and test two models. One model assumes that common ground is involved in initial utterance planning, while the other model assumes that it only plays a role in monitoring. To compare these models, we focus on common ground as evidenced in physical co-presence. We had speakers describe objects for listeners in a modified version of the referential communication task. While descriptions under no time constraints appeared to incorporate common ground with the listener, common ground was not used when the speakers were under time pressure. These results suggest that speakers do not engage in audience design in the initial planning of utterances; instead, they monitor those plans for violations of common ground.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6IKZ4LDJ/Horton and Keysar - 1996 - When do speakers take into account common ground.pdf}
}

@article{horton2002,
  ids = {hortonSpeakersOExperiencesAudience2002a},
  title = {{{Speakers{\~O}}} Experiences and Audience Design: {{Knowing}} When and Knowing How to Adjust Utterances to Addresseesq},
  author = {Horton, William S and Gerrig, Richard J},
  year = {2002},
  journal = {Journal of Memory and Language},
  pages = {18},
  date-modified = {2022-02-01 10:44:32 -0800},
  langid = {english},
  keywords = {read}
}

@article{horton2002a,
  title = {Speakers' Experiences and Audience Design: Knowing When and Knowing How to Adjust Utterances to Addressees},
  shorttitle = {Speakers' Experiences and Audience Design},
  author = {Horton, William S. and Gerrig, Richard J.},
  year = {2002},
  month = nov,
  journal = {Journal of Memory and Language},
  volume = {47},
  number = {4},
  pages = {589--606},
  issn = {0749-596X},
  doi = {10.1016/S0749-596X(02)00019-0},
  urldate = {2023-06-27},
  abstract = {In this paper, we develop an account of the types of experiences through which speakers learn to design their utterances for particular addressees. We argue that there are two important aspects of conversational situations relevant to considerations of audience design. First, speakers must become aware that audience design is necessary in the current setting. Second, they must frequently overcome other tendencies toward consistency and brevity of expression. To assess the impact of both of these factors, we conducted a referential communication experiment in which Directors described arrays of picture cards for two independent Matchers. In the early rounds, both Matchers were present and each possessed a different subset of the Directors' cards. In later rounds, only one of the two Matchers was present at a time and worked with the entire set of cards. We evaluated the degree to which Directors' descriptions showed evidence of audience design by focusing on critical rounds when the Directors described cards that the current Matcher had not previously shared. Directors generally appeared sensitive to the distinction between shared and nonshared items. Additionally, there was more evidence of adjustment at the second partner change, suggesting that the Directors had learned something about the kinds of descriptions required in this situation. Our results suggest that it is important to consider the nature of speakers' experiences of interacting in a particular situation when making claims about the presence or absence of audience design.},
  langid = {english},
  keywords = {Audience design,Conversation,Language production,read,Reference},
  file = {/home/vboyce/Zotero/storage/2EQW68JN/Horton and Gerrig - 2002 - Speakers’ experiences and audience design knowing.pdf}
}

@article{horton2005,
  ids = {hortonImpactMemoryDemands2005a},
  title = {The Impact of Memory Demands on Audience Design during Language Production},
  author = {Horton, William S. and Gerrig, Richard J.},
  year = {2005},
  month = jun,
  journal = {Cognition},
  volume = {96},
  number = {2},
  pages = {127--142},
  issn = {00100277},
  doi = {10.1016/j.cognition.2004.07.001},
  urldate = {2021-05-11},
  abstract = {Speakers often tailor their utterances to the needs of particular addressees---a process called audience design. We argue that important aspects of audience design can be understood as emergent features of ordinary memory processes. This perspective contrasts with earlier views that presume special processes or representations. To support our account, we present a study in which Directors engaged in a referential communication task with two independent Matchers. Over several rounds, the Directors instructed the Matchers how to arrange a set of picture cards. For half the triads, the Directors' card categories were initially distributed orthogonally by Matcher (e.g. Directors described birds and dogs with one Matcher and fish and frogs with the other). For the other triads, the Directors' card categories initially overlapped across Matchers (e.g. Directors described two members of each category with each Matcher). We predicted that the orthogonal configuration would more readily allow Directors to encode associations between particular cards and particular Matchers---and thus allow those Directors to provide more evidence for audience design. Content analyses of Directors' utterances from two final rounds supported our prediction. We suggest that audience design depends on the memory representations to which speakers have ready access given the time constraints of routine conversation.},
  langid = {english},
  keywords = {Audience design,Communication,Language production,Memory,read},
  file = {/home/vboyce/Zotero/storage/2MSI4V8B/Horton and Gerrig - 2005 - The impact of memory demands on audience design du.pdf}
}

@article{huang2009,
  title = {Online Interpretation of Scalar Quantifiers: {{Insight}} into the Semantics--Pragmatics Interface},
  shorttitle = {Online Interpretation of Scalar Quantifiers},
  author = {Huang, Yi Ting and Snedeker, Jesse},
  year = {2009},
  month = may,
  journal = {Cognitive Psychology},
  volume = {58},
  number = {3},
  pages = {376--415},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2008.09.001},
  urldate = {2025-01-16},
  abstract = {Scalar implicature has served as a test case for exploring the relations between semantic and pragmatic processes during language comprehension. Most studies have used reaction time methods and the results have been variable. In these studies, we use the visual-world paradigm to investigate implicature. We recorded participants' eye movements during commands like ``Point to the girl that has some of the socks'' in the presence of a display in which one girl had two of four socks and another had three of three soccer balls. These utterances contained an initial period of ambiguity in which the semantics of some was compatible with both characters. This ambiguity could be immediately resolved by a pragmatic implicature which would restrict some to a proper subset. Instead in Experiments 1 and 2, we found that participants were substantially delayed, suggesting a lag between semantic and pragmatic processing. In Experiment 3, we examined interpretations of some when competitors were inconsistent with the semantics (girl with socks vs. girl with no socks). We found quick resolution of the target, suggesting that previous delays were specifically linked to pragmatic analysis.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/C3QI8J8W/Huang and Snedeker - 2009 - Online interpretation of scalar quantifiers Insight into the semantics–pragmatics interface.pdf}
}

@article{huang2009a,
  title = {Semantic Meaning and Pragmatic Interpretation in 5-Year-Olds: {{Evidence}} from Real-Time Spoken Language Comprehension.},
  shorttitle = {Semantic Meaning and Pragmatic Interpretation in 5-Year-Olds},
  author = {Huang, Yi Ting and Snedeker, Jesse},
  year = {2009},
  month = nov,
  journal = {Developmental Psychology},
  volume = {45},
  number = {6},
  pages = {1723--1739},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0016704},
  urldate = {2025-01-16},
  abstract = {Recent research on children's inferencing has found that while adults typically adopt the pragmatic interpretation of some (implying not all), five- to nine-year-olds often prefer the semantic interpretation of the quantifier (meaning possibly all). Do these failures reflect a breakdown of pragmatic competence or the metalinguistic demands of prior tasks? In three experiments, we used the visual-world eye-tracking paradigm to elicit an implicit measure of adult's and children's abilities to generate scalar implicatures. While adults' eye-movements indicated that they had interpreted some with the pragmatic inference, children's looks suggest that they persistently interpreted some as compatible with all (Experiment 1). Nevertheless, both adults and children were able to quickly reject competitors that were inconsistent with the semantics of some, confirming the sensitivity of the paradigm (Experiment 2). Finally, adults, but not children, successfully distinguished between situations that violated the scalar implicature and ones that did not (Experiment 3). These data demonstrate that children interpret quantifiers based on their semantic content and fail to generate scalar implicatures during online language comprehension.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/NSYFDU97/Huang and Snedeker - 2009 - Semantic meaning and pragmatic interpretation in 5-year-olds Evidence from real-time spoken languag.pdf}
}

@article{ibarra2016,
  title = {The {{Flexibility}} of {{Conceptual Pacts}}: {{Referring Expressions Dynamically Shift}} to {{Accommodate New Conceptualizations}}},
  shorttitle = {The {{Flexibility}} of {{Conceptual Pacts}}},
  author = {Ibarra, Alyssa and Tanenhaus, Michael K.},
  year = {2016},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {7},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.00561},
  urldate = {2020-10-03},
  abstract = {In a classic paper, Brennan and Clark argued that when interlocutors agree on a name for an object, they are forming a temporary agreement on how to conceptualize that object; that is, they are forming a conceptual pact. The literature on conceptual pacts has largely focused on the costs and benefits of breaking and maintaining lexical precedents, and the degree to which they might be partner-specific. The research presented here focuses on a question about conceptual pacts that has been largely neglected in the literature: To what extent are conceptual pacts specific to the local context of the interaction? If conceptual pacts are indeed temporary, then when the local context changes in ways that are accessible to participants, we would expect participants to seamlessly shift to referential expressions that reflect novel conceptualizations. Two experiments examined how referential forms change across context in collaborative, task-oriented dialog between na{\"i}ve participants. In Experiment 1, names for parts of an unknown object were established in an ``item'' identification stage (e.g., a shape that looked like a wrench was called ``the wrench''). In a second ``build'' stage, that name was often supplanted by an object-oriented name, e.g., the ``leg.'' These changes happened abruptly and without negotiation. In Experiment 2, interlocutors manipulated clip art and more abstract tangram pictures in a ``slider'' puzzle to arrange the objects into a target configuration. On some trials moving an object revealed a picture that could be construed as a contrast competitor, e.g., a clip art picture of a camel after ``the camel'' had been negotiated as a name for a tangram shape, or vice versa. As would be expected, modification rates increased when a potential contrast was revealed. More strikingly, the degree to which a name had been negotiated or the frequency with which it had been used did not affect the likelihood that the revealed shape would be considered as a potential contrast. We find little evidence that names that are introduced as part of a conceptual pact persist when either the task goals or informational needs change. Rather, conceptual pacts are fluid temporary agreements.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6IH4D4X7/Ibarra and Tanenhaus - 2016 - The Flexibility of Conceptual Pacts Referring Exp.pdf}
}

@inproceedings{ji2022a,
  title = {Abstract {{Visual Reasoning}} with {{Tangram Shapes}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert and Artzi, Yoav},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  year = {2022},
  month = dec,
  pages = {582--601},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.38},
  urldate = {2024-10-01},
  abstract = {We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with {\textbackslash}textgreater1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs.},
  file = {/home/vboyce/Zotero/storage/A4TYM6N2/Ji et al. - 2022 - Abstract Visual Reasoning with Tangram Shapes.pdf}
}

@inproceedings{kang2020,
  title = {Incorporating {{Pragmatic Reasoning Communication}} into {{Emergent Language}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kang, Yipeng and Wang, Tonghan and {de Melo}, Gerard},
  year = {2020},
  volume = {33},
  pages = {10348--10359},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-01-13},
  abstract = {Emergentism and pragmatics are two research fields that study the dynamics of linguistic communication along quite different timescales and intelligence levels. From the perspective of multi-agent reinforcement learning, they correspond to stochastic games with reinforcement training and stage games with opponent awareness, respectively. Given that their combination has been explored in linguistics, in this work, we combine computational models of short-term mutual reasoning-based pragmatics with long-term language emergentism. We explore this for agent communication in two settings, referential games and Starcraft II, assessing the relative merits of different kinds of mutual reasoning pragmatics models both empirically and theoretically. Our results shed light on their importance for making inroads towards getting more natural, accurate, robust, fine-grained, and succinct utterances.},
  file = {/home/vboyce/Zotero/storage/XKZN8YJS/Kang et al. - 2020 - Incorporating Pragmatic Reasoning Communication into Emergent Language.pdf}
}

@article{kao2014,
  ids = {kaoFormalizingPragmaticsMetaphora},
  title = {Formalizing the {{Pragmatics}} of {{Metaphor Understanding}}},
  author = {Kao, Justine T},
  year = {2014},
  journal = {CogSci},
  abstract = {While the ubiquity and importance of nonliteral language are clear, people's ability to use and understand it remains a mystery. Metaphor in particular has been studied extensively across many disciplines in cognitive science. One approach focuses on the pragmatic principles that listeners utilize to infer meaning from metaphorical utterances. While this approach has generated a number of insights about how people understand metaphor, to our knowledge there is no formal model showing that effects in metaphor understanding can arise from basic principles of communication. Building upon recent advances in formal models of pragmatics, we describe a computational model that uses pragmatic reasoning to interpret metaphorical utterances. We conduct behavioral experiments to evaluate the model's performance and show that our model produces metaphorical interpretations that closely fit behavioral data. We discuss implications of the model for metaphor understanding, principles of communication, and formal models of language understanding.},
  langid = {english},
  keywords = {read}
}

@article{keen2003,
  title = {Representation of {{Objects}} and {{Events}}: {{Why Do Infants Look So Smart}} and {{Toddlers Look So Dumb}}?},
  shorttitle = {Representation of {{Objects}} and {{Events}}},
  author = {Keen, Rachel},
  year = {2003},
  month = jun,
  journal = {Current Directions in Psychological Science},
  volume = {12},
  number = {3},
  pages = {79--83},
  publisher = {SAGE Publications Inc},
  issn = {0963-7214},
  doi = {10.1111/1467-8721.01234},
  urldate = {2025-01-16},
  abstract = {Research has demonstrated that very young infants can discriminate between visual events that are physically impossible versus possible. These findings suggest that infants have knowledge of physical laws concerning solidity and continuity. However, research with 2-year-olds has shown that they cannot solve simple problems involving search for a hidden object, even though these problems require the same knowledge. These apparently inconsistent findings raise questions about the interpretation of both data sets. This discrepancy may be resolved by examining differences in task demands.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/73JCUFRX/Keen - 2003 - Representation of Objects and Events Why Do Infants Look So Smart and Toddlers Look So Dumb.pdf}
}

@article{kemp2018,
  title = {Semantic {{Typology}} and {{Efficient Communication}}},
  author = {Kemp, Charles and Xu, Yang and Regier, Terry},
  year = {2018},
  month = jan,
  journal = {Annual Review of Linguistics},
  volume = {4},
  number = {1},
  pages = {109--128},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-011817-045406},
  urldate = {2020-06-15},
  abstract = {Cross-linguistic work on domains including kinship, color, folk biology, number, and spatial relations has documented the different ways in which languages carve up the world into named categories. Although word meanings vary widely across languages, unrelated languages often have words with similar or identical meanings, and many logically possible meanings are never observed. We review work suggesting that this pattern of constrained variation is explained in part by the need for words to support efficient communication. This work includes several recent studies that have formalized efficient communication in computational terms, and a larger set of studies, both classic and recent, that do not explicitly appeal to efficient communication but are nevertheless consistent with this notion. The efficient communication framework has implications for the relationship between language and culture and for theories of language change, and we draw out some of these connections.},
  langid = {english},
  keywords = {read}
}

@article{keysar2000,
  title = {Taking {{Perspective}} in {{Conversation}}: {{The Role}} of {{Mutual Knowledge}} in {{Comprehension}}},
  shorttitle = {Taking {{Perspective}} in {{Conversation}}},
  author = {Keysar, Boaz and Barr, Dale J. and Balin, Jennifer A. and Brauner, Jason S.},
  year = {2000},
  month = jan,
  journal = {Psychological Science},
  volume = {11},
  number = {1},
  pages = {32--38},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00211},
  urldate = {2023-01-19},
  abstract = {When people interpret language, they can reduce the ambiguity of linguistic expressions by using information about perspective: the speaker's, their own, or a shared perspective. In order to investigate the mental processes that underlie such perspective taking, we tracked people's eye movements while they were following instructions to manipulate objects. The eye fixation data in two experiments demonstrate that people do not restrict the search for referents to mutually known objects. Eye movements indicated that addressees considered objects as potential referents even when the speaker could not see those objects, requiring addressees to use mutual knowledge to correct their interpretation. Thus, people occasionally use an egocentric heuristic when they comprehend. We argue that this egocentric heuristic is successful in reducing ambiguity, though it could lead to a systematic error.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/B2U5X3H9/Keysar et al. - 2000 - Taking Perspective in Conversation The Role of Mu.pdf}
}

@article{khani2018,
  title = {Planning, {{Inference}} and {{Pragmatics}} in {{Sequential Language Games}}},
  author = {Khani, Fereshte and Goodman, Noah D. and Liang, Percy},
  year = {2018},
  month = may,
  journal = {arXiv:1805.11774 [cs]},
  eprint = {1805.11774},
  primaryclass = {cs},
  urldate = {2020-05-04},
  abstract = {We study sequential language games in which two players, each with private information, communicate to achieve a common goal. In such games, a successful player must (i) infer the partner's private information from the partner's messages, (ii) generate messages that are most likely to help with the goal, and (iii) reason pragmatically about the partner's strategy. We propose a model that captures all three characteristics and demonstrate their importance in capturing human behavior on a new goal-oriented dataset we collected using crowdsourcing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/3DA8IU45/Khani et al. - 2018 - Planning, Inference and Pragmatics in Sequential L.pdf;/home/vboyce/Zotero/storage/N5FWZD8L/1805.html}
}

@article{kirby2015,
  title = {Compression and Communication in the Cultural Evolution of Linguistic Structure},
  author = {Kirby, Simon and Tamariz, Monica and Cornish, Hannah and Smith, Kenny},
  year = {2015},
  month = aug,
  journal = {Cognition},
  volume = {141},
  pages = {87--102},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2015.03.016},
  urldate = {2023-06-13},
  abstract = {Language exhibits striking systematic structure. Words are composed of combinations of reusable sounds, and those words in turn are combined to form complex sentences. These properties make language unique among natural communication systems and enable our species to convey an open-ended set of messages. We provide a cultural evolutionary account of the origins of this structure. We show, using simulations of rational learners and laboratory experiments, that structure arises from a trade-off between pressures for compressibility (imposed during learning) and expressivity (imposed during communication). We further demonstrate that the relative strength of these two pressures can be varied in different social contexts, leading to novel predictions about the emergence of structured behaviour in the wild.},
  langid = {english},
  keywords = {Cultural transmission,Iterated learning,Language evolution,read},
  file = {/home/vboyce/Zotero/storage/PAEMZ5V9/Kirby et al. - 2015 - Compression and communication in the cultural evol.pdf}
}

@article{koymen2014,
  title = {Young Children Create Partner-Specific Referential Pacts with Peers.},
  author = {K{\"o}ymen, Bahar and Schmerse, Daniel and Lieven, Elena and Tomasello, Michael},
  year = {2014},
  journal = {Developmental Psychology},
  volume = {50},
  number = {10},
  pages = {2334--2342},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0037837},
  urldate = {2023-10-07},
  abstract = {In 2 studies, we investigated how peers establish a referential pact to call something, for example, a cushion versus a pillow (both equally felicitous). In Study 1, pairs of 4- and 6-year-old German-speaking peers established a referential pact for an artifact, for example, a woman's shoe, in a referential communication task. Six-year-olds, but not 4-year-olds, continued to use these same expressions with the same partner (even when they were overinformative) but shifted to simpler expressions, for example, shoe, with a new partner. In Study 2, both age groups were successful in establishing such partnerspecific referential pacts with a peer when using a proper name. These results suggest that even preschool children appreciate something of the conventional nature of linguistic expressions, with significant flexibility emerging between ages 4 and 6.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/VGYTAP9S/Köymen et al. - 2014 - Young children create partner-specific referential.pdf}
}

@article{krauss1964,
  ids = {kraussChangesReferencePhrases1964a},
  title = {Changes in Reference Phrases as a Function of Frequency of Usage in Social Interaction: A Preliminary Study},
  shorttitle = {Changes in Reference Phrases as a Function of Frequency of Usage in Social Interaction},
  author = {Krauss, Robert M. and Weinheimer, Sidney},
  year = {1964},
  month = jan,
  journal = {Psychonomic Science},
  volume = {1},
  number = {1-12},
  pages = {113--114},
  issn = {0033-3131, 2197-9952},
  doi = {10.3758/BF03342817},
  urldate = {2021-07-31},
  abstract = {Pairs of subjects interacted in a problem-solving task which required them to communicate about ambiguous figures. The length of the reference phrase for each figure was calculated. A negative relationship was found between the frequency with which a figure was referred to and the mean length of its reference phrase. Problem This paper reports a preliminary study in a program of research on the dynamics of linguistic changes which occur in the course of social interaction. The present study is concerned with the manner in which reference phrases (verbal labels) given to ambiguous figures change during interaction.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/7ZIKXA5W/Krauss and Weinheimer - 1964 - Changes in reference phrases as a function of freq.pdf;/home/vboyce/Zotero/storage/FRG2PWIY/Krauss and Weinheimer - 1964 - Changes in reference phrases as a function of freq.pdf;/home/vboyce/Zotero/storage/I4DBSZ58/Krauss and Weinheimer - 1964 - Changes in reference phrases as a function of freq.pdf}
}

@article{krauss1966,
  title = {Concurrent Feedback, Confirmation, and the Encoding of Referents in Verbal Communication.},
  author = {Krauss, Robert M. and Weinheimer, Sidney},
  year = {1966},
  journal = {Journal of Personality and Social Psychology},
  volume = {4},
  number = {3},
  pages = {343--346},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/h0023705},
  urldate = {2022-02-01},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/P4ZS8MPV/Krauss and Weinheimer - 1966 - Concurrent feedback, confirmation, and the encodin.pdf;/home/vboyce/Zotero/storage/WWWEXLAC/Krauss and Weinheimer - 1966 - Concurrent feedback, confirmation, and the encodin.pdf}
}

@article{krauss1967,
  title = {Effects of Transmission Delay and Access Delay on the Efficiency of Verbal Communication},
  author = {Krauss, Robert M and Bricker, Peter D},
  year = {1967},
  journal = {The Journal of the Acoustical Society of America},
  volume = {41},
  number = {2},
  pages = {286--292},
  urldate = {2017-10-15}
}

@article{krauss1969,
  title = {The {{Development}} of {{Communication}}: {{Competence}} as a {{Function}} of {{Age}}},
  shorttitle = {The {{Development}} of {{Communication}}},
  author = {Krauss, Robert M. and Glucksberg, Sam},
  year = {1969},
  journal = {Child Development},
  volume = {40},
  number = {1},
  eprint = {1127172},
  eprinttype = {jstor},
  pages = {255--266},
  publisher = {[Wiley, Society for Research in Child Development]},
  issn = {0009-3920},
  doi = {10.2307/1127172},
  urldate = {2022-06-06},
  abstract = {2 experiments are reported. In the first, pairs of children in kindergarten, first, third, and fifth grades played a communication game which required that they develop names to refer to unique graphic figures. In the second experiment, names which had been provided by Ss in Experiment I were given to adult Ss, who were asked to match the names to the figures which initially had elicited them. In Experiment I, all groups began at roughly the same level of communication accuracy, but the older Ss showed a rapid decrease in the number of errors over repetitive trials, while kindergartners' performance showed no improvement. In experiment II, the accuracy of adult Ss varied as a positive function of the age of the child who had provided the name. None of several lexical indexes applied to the names was related to the accuracy with which the name was responded to, irrespective of the speaker's age.},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/SMSJVI8K/Krauss and Glucksberg - 1969 - The Development of Communication Competence as a .pdf}
}

@article{krauss1977,
  title = {Social and {{Nonsocial Speech}}},
  author = {Krauss, Robert M. and Glucksberg, Sam},
  year = {1977},
  journal = {Scientific American},
  volume = {236},
  number = {2},
  eprint = {24953896},
  eprinttype = {jstor},
  pages = {100--105},
  publisher = {Scientific American, a division of Nature America, Inc.},
  issn = {0036-8733},
  urldate = {2022-06-08},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/Q5G3ZS77/Krauss and Glucksberg - 1977 - Social and Nonsocial Speech.pdf}
}

@article{krauss1977a,
  title = {The Role of Audible and Visible Back-Channel Responses in Interpersonal Communication.},
  author = {Krauss, Robert M and Garlock, Connie M and Bricker, Peter D and McMahon, Lee E},
  year = {1977},
  journal = {Journal of Personality and Social Psychology},
  volume = {35},
  number = {7},
  pages = {523},
  urldate = {2017-09-14}
}

@article{kraut1982,
  title = {Listener Responsiveness and the Coordination of Conversation.},
  author = {Kraut, Robert E and Lewis, Steven H and Swezey, Lawrence W},
  year = {1982},
  journal = {Journal of personality and social psychology},
  volume = {43},
  number = {4},
  pages = {718},
  publisher = {American Psychological Association}
}

@misc{le2022,
  title = {Referring {{Expressions}} with {{Rational Speech Act Framework}}: {{A Probabilistic Approach}}},
  shorttitle = {Referring {{Expressions}} with {{Rational Speech Act Framework}}},
  author = {Le, Hieu and Daryanto, Taufiq and Zhafransyah, Fabian and Wijaya, Derry and Coppock, Elizabeth and Chin, Sang},
  year = {2022},
  month = may,
  number = {arXiv:2205.07795},
  eprint = {2205.07795},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.07795},
  urldate = {2025-01-13},
  abstract = {This paper focuses on a referring expression generation (REG) task in which the aim is to pick out an object in a complex visual scene. One common theoretical approach to this problem is to model the task as a two-agent cooperative scheme in which a `speaker' agent would generate the expression that best describes a targeted area and a `listener' agent would identify the target. Several recent REG systems have used deep learning approaches to represent the speaker/listener agents. The Rational Speech Act framework (RSA), a Bayesian approach to pragmatics that can predict human linguistic behavior quite accurately, has been shown to generate high quality and explainable expressions on toy datasets involving simple visual scenes. Its application to large scale problems, however, remains largely unexplored. This paper applies a combination of the probabilistic RSA framework and deep learning approaches to larger datasets involving complex visual scenes in a multi-step process with the aim of generating better-explained expressions. We carry out experiments on the RefCOCO and RefCOCO+ datasets and compare our approach with other end-to-end deep learning approaches as well as a variation of RSA to highlight our key contribution. Experimental results show that while achieving lower accuracy than SOTA deep learning methods, our approach outperforms similar RSA approach in human comprehension and has an advantage over end-to-end deep learning under limited data scenario. Lastly, we provide a detailed analysis on the expression generation process with concrete examples, thus providing a systematic view on error types and deficiencies in the generation process and identifying possible areas for future improvements.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/vboyce/Zotero/storage/B5RRZG2C/Le et al. - 2022 - Referring Expressions with Rational Speech Act Framework A Probabilistic Approach.pdf;/home/vboyce/Zotero/storage/CKRS5BDG/2205.html}
}

@article{leeuw2023,
  title = {{{jsPsych}}: {{Enabling}} an {{Open-Source Collaborative Ecosystem}} of {{Behavioral Experiments}}},
  shorttitle = {{{jsPsych}}},
  author = {de Leeuw, Joshua R. and Gilbert, Rebecca A. and Luchterhandt, Bj{\"o}rn},
  year = {2023},
  month = may,
  journal = {Journal of Open Source Software},
  volume = {8},
  number = {85},
  pages = {5351},
  issn = {2475-9066},
  doi = {10.21105/joss.05351},
  urldate = {2025-01-14},
  abstract = {de Leeuw et al., (2023). jsPsych: Enabling an Open-Source Collaborative Ecosystem of Behavioral Experiments. Journal of Open Source Software, 8(85), 5351, https://doi.org/10.21105/joss.05351},
  langid = {english},
  file = {/home/vboyce/Zotero/storage/VFKYTD3I/Leeuw et al. - 2023 - jsPsych Enabling an Open-Source Collaborative Ecosystem of Behavioral Experiments.pdf}
}

@misc{leung2023,
  title = {Parents Scaffold the Formation of Conversational Pacts with Their Children},
  author = {Leung, Ashley and Yurovsky, Daniel and Hawkins, Robert},
  year = {2023},
  month = apr,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/8u4qa},
  urldate = {2023-06-13},
  abstract = {Adults readily form conversational pacts, or temporary agreements about referent names, over the course of conversation. Young children notoriously have difficulty forming pacts with peers, but the root cause of such difficulty has remained unclear. Here, we aim to tease apart the component processes of referential pact formation that may be implicated. In Experiment 1, we show that children (ages 4, 6, 8) are, in fact, able to coordinate on increasingly accurate and efficient pacts with parents in a director-matcher task. We analyze the interactional features that account for their success, finding that parents spontaneously initiate more clarification exchanges with younger children who, in turn, are more likely to adapt to labels introduced by the parent. We then examine whether the benefit of such interactional scaffolding primarily emerges through overcoming childrens' difficulties with comprehension (Experiment 2) or production (Experiment 3). Contrary to classical views attributing childrens' coordination failures to lexical rigidity or perspective-taking, these result support the idea that children readily form pacts when scaffolding from parents helps overcome their production difficulties.},
  langid = {american},
  keywords = {Cognitive Psychology,Developmental Psychology,Language,Language Aquisition,read,Social and Behavioral Sciences,Social Development},
  file = {/home/vboyce/Zotero/storage/IL9EMXI3/Leung et al. - 2023 - Parents scaffold the formation of conversational p.pdf}
}

@article{leung2024,
  title = {Parents Spontaneously Scaffold the Formation of Conversational Pacts with Their Children},
  author = {Leung, Ashley and Yurovsky, Daniel and Hawkins, Robert D.},
  year = {2024},
  journal = {Child Development},
  volume = {n/a},
  number = {n/a},
  issn = {1467-8624},
  doi = {10.1111/cdev.14186},
  urldate = {2024-12-06},
  abstract = {Adults readily coordinate on temporary pacts about how to refer to things in conversation. Young children are also capable of forming pacts with peers given appropriate experimenter intervention. Here, we investigate whether parents may spontaneously provide a similar kind of scaffolding with U.S. children in a director--matcher task (N = 201, 49\% female; ages 4, 6, 8). In Experiment 1, we show that parents initiate more clarification exchanges with younger children who, in turn, are more likely to adopt labels introduced by the parent. We then examine whether the benefit of such scaffolding acts primarily through childrens' difficulties with comprehension (Experiment 2) or production (Experiment 3). Our findings suggest that parents primarily scaffold pacts by easing children's production difficulties, modeling cooperative communication.},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/2DV3EMHX/Leung et al. - Parents spontaneously scaffold the formation of conversational pacts with their children.pdf;/home/vboyce/Zotero/storage/FXKEKZJ2/cdev.html}
}

@book{lewis1969,
  title = {Convention: {{A}} Philosophical Study},
  author = {Lewis, David},
  year = {1969},
  publisher = {John Wiley \& Sons}
}

@article{macdonald1994,
  title = {Probabilistic Constraints and Syntactic Ambiguity Resolution},
  author = {MacDonald, Maryellen C.},
  year = {1994},
  month = may,
  journal = {Language and Cognitive Processes},
  volume = {9},
  number = {2},
  pages = {157--201},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690969408402115},
  urldate = {2023-10-20},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/4X4M95AS/MacDonald - 1994 - Probabilistic constraints and syntactic ambiguity .pdf}
}

@article{macdonald2013,
  title = {How Language Production Shapes Language Form and Comprehension},
  author = {MacDonald, Maryellen C.},
  year = {2013},
  journal = {Frontiers in Psychology},
  volume = {4},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00226},
  urldate = {2021-04-22},
  abstract = {Language production processes can provide insight into how language comprehension works and language typology---why languages tend to have certain characteristics more often than others. Drawing on work in memory retrieval, motor planning, and serial order in action planning, the Production-Distribution-Comprehension (PDC) account links work in the fields of language production, typology, and comprehension: 1) faced with substantial computational burdens of planning and producing utterances, language producers implicitly follow three biases in utterance planning that promote word order choices that reduce these burdens, thereby improving production fluency. 2) These choices, repeated over many utterances and individuals, shape the distributions of utterance forms in language. The claim that language form stems in large degree from producers' attempts to mitigate utterance planning difficulty is contrasted with alternative accounts in which form is driven by language use more broadly, language acquisition processes, or producers' attempts to create language forms that are easily understood by comprehenders. 3) Language perceivers implicitly learn the statistical regularities in their linguistic input, and they use this prior experience to guide comprehension of subsequent language. In particular, they learn to predict the sequential structure of linguistic signals, based on the statistics of previously-encountered input. Thus key aspects of comprehension behavior are tied to lexico-syntactic statistics in the language, which in turn derive from utterance planning biases promoting production of comparatively easy utterance forms over more difficult ones. This approach contrasts with classic theories in which comprehension behaviors are attributed to innate design features of the language comprehension system and associated working memory. The PDC instead links basic features of comprehension to a different source: production processes that shape language form.},
  langid = {english},
  keywords = {language acquisition,Language comprehension,Language production,Language typology,motor control,read,serial order,syntax,useful,working memory},
  file = {/home/vboyce/Zotero/storage/EB5JXATX/MacDonald - 2013 - How language production shapes language form and c.pdf}
}

@incollection{macmillan2004,
  title = {Communication Overhead: {{The}} Hidden Cost of Team Cognition.},
  booktitle = {Team Cognition: {{Understanding}} the Factors That Drive Process and Performance.},
  author = {MacMillan, Jean and Entin, Elliot E. and Serfaty, Daniel},
  year = {2004},
  pages = {61--82},
  publisher = {American Psychological Association},
  address = {Washington, DC, US},
  doi = {10.1037/10690-004},
  urldate = {2023-07-25},
  abstract = {To function effectively, a team must act as an information-processing unit, maintaining an awareness of the situation or context in which it is functioning and acquiring and using information to act in that situation. This team cognition differs from individual cognition, of course, because each team member acts as an individual information processor. For a team to act in concert to achieve common goals, the team must have shared information about both the situation and the other team members. Team cognition thus requires communication-a process that has no direct analog in individual cognition-in order for the team to build and maintain a shared mental model of the situation. Because communication is essential to team performance, effective team cognition has a communication "overhead" associated with the exchange of information among team members. Communication requires both time and cognitive resources, and, to the extent that communication can be made less necessary or more efficient, team performance can benefit as a result. In this chapter we present a theoretical framework that describes the relationship between team communication behaviors and team performance. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  isbn = {1-59147-103-6 (Hardcover)},
  keywords = {*Cognitions,*Communication,*Group Performance,Teams}
}

@article{matthews2006,
  title = {The Effect of Perceptual Availability and Prior Discourse on Young Children's Use of Referring Expressions},
  author = {Matthews, Danielle and Lieven, Elena and Theakston, Anna and Tomasello, Michael},
  year = {2006},
  month = jul,
  journal = {Applied Psycholinguistics},
  volume = {27},
  number = {3},
  pages = {403--422},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716406060334},
  urldate = {2025-01-06},
  abstract = {Choosing appropriate referring expressions requires assessing whether a referent is ``available'' to the addressee either perceptually or through discourse. In Study 1, we found that 3- and 4-year-olds, but not 2-year-olds, chose different referring expressions (noun vs. pronoun) depending on whether their addressee could see the intended referent or not. In Study 2, in more neutral discourse contexts than previous studies, we found that 3- and 4-year-olds clearly differed in their use of referring expressions according to whether their addressee had already mentioned a referent. Moreover, 2-yearolds responded with more naming constructions when the referent had not been mentioned previously. This suggests that, despite early social--cognitive developments, (a) it takes time to master the given/new contrast linguistically, and (b) children understand the contrast earlier based on discourse, rather than perceptual context.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/ZAE3K5DV/Matthews et al. - 2006 - The effect of perceptual availability and prior discourse on young children's use of referring expre.pdf}
}

@article{matthews2010,
  title = {What's in a Manner of Speaking? {{Children}}'s Sensitivity to Partner-Specific Referential Precedents.},
  shorttitle = {What's in a Manner of Speaking?},
  author = {Matthews, Danielle and Lieven, Elena and Tomasello, Michael},
  year = {2010},
  journal = {Developmental Psychology},
  volume = {46},
  number = {4},
  pages = {749--760},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0019657},
  urldate = {2023-10-07},
  abstract = {Do young children form ``referential pacts''? If a person has referred to an object with a certain term (e.g., the horse), will children expect this person to use this term in the future but allow others to use a different expression (e.g., the pony)? One hundred twenty-eight children between 3 and 5 years old co-operated with an experimenter (E1) to move toys to new locations on a shelf. E1 established referential terms for all toys in a warm-up game. Then, either the original partner, E1, or a new partner, E2, played a second game with the same toys. In this game, the experimenters referred to toys using either their original terms from the warm-up game or new terms. Children were slower to react to new terms than old, and this difference in reaction times was greater in the original partner condition (but only on the first trial). Children sometimes protested at the use of new terms, doing so regardless of their interlocutor's identity. We contrast these findings with those for adults and discuss their implications for the debate regarding the nature of referential pacts.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/F5W3G3DB/Matthews et al. - 2010 - What's in a manner of speaking Children's sensiti.pdf}
}

@article{matthews2012,
  title = {Two- and {{Four}}-{{Year}}-{{Olds Learn}} to {{Adapt Referring Expressions}} to {{Context}}: {{Effects}} of {{Distracters}} and {{Feedback}} on {{Referential Communication}}},
  shorttitle = {Two- and {{Four}}-{{Year}}-{{Olds Learn}} to {{Adapt Referring Expressions}} to {{Context}}},
  author = {Matthews, Danielle and Butcher, Jessica and Lieven, Elena and Tomasello, Michael},
  year = {2012},
  month = apr,
  journal = {Topics in Cognitive Science},
  volume = {4},
  number = {2},
  pages = {184--210},
  issn = {1756-8757, 1756-8765},
  doi = {10.1111/j.1756-8765.2012.01181.x},
  urldate = {2025-01-06},
  abstract = {Children often refer to things ambiguously but learn not to from responding to clarification requests. We review and explore this learning process here. In Study 1, eighty-four 2- and 4year-olds were tested for their ability to request stickers from either (a) a small array with one dissimilar distracter or (b) a large array containing similar distracters. When children made ambiguous requests, they received either general feedback or specific questions about which of two options they wanted. With training, children learned to produce more complex object descriptions and did so faster in the specific feedback condition. They also tended to provide more information when requesting stickers from large arrays. In Study 2, we varied only distracter similarity during training and then varied array size in a generalization test. Children found it harder to learn in this case. In the generalization test, 4-year-olds were more likely to provide information (a) when it was needed because distracters were similar to the target and (b) when the array size was greater (regardless of need for information). We discuss how clear cues to potential ambiguity are needed for children to learn to tailor their referring expression to context and how several cues of heuristic value (e.g., more distracters {$>$} say more) can promote the efficiency of communication while language is developing. Finally, we consider whether it would be worthwhile drawing on the human learning process when developing algorithms for the production of referring expressions.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/NBTSZLSG/Matthews et al. - 2012 - Two‐ and Four‐Year‐Olds Learn to Adapt Referring Expressions to Context Effects of Distracters and.pdf}
}

@article{meehl1990,
  title = {Appraising and {{Amending Theories}}: {{The Strategy}} of {{Lakatosian Defense}} and {{Two Principles}} That {{Warrant It}}},
  shorttitle = {Appraising and {{Amending Theories}}},
  author = {Meehl, Paul E.},
  year = {1990},
  month = apr,
  journal = {Psychological Inquiry},
  volume = {1},
  number = {2},
  pages = {108--141},
  issn = {1047-840X, 1532-7965},
  doi = {10.1207/s15327965pli0102_1},
  urldate = {2024-02-05},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/RNWVLR4B/Meehl - 1990 - Appraising and Amending Theories The Strategy of .pdf}
}

@article{metzing2003,
  title = {When Conceptual Pacts Are Broken: {{Partner-specific}} Effects on the Comprehension of Referring Expressions},
  shorttitle = {When Conceptual Pacts Are Broken},
  author = {Metzing, Charles and Brennan, Susan E.},
  year = {2003},
  month = aug,
  journal = {Journal of Memory and Language},
  volume = {49},
  number = {2},
  pages = {201--213},
  issn = {0749-596X},
  doi = {10.1016/S0749-596X(03)00028-7},
  urldate = {2023-08-08},
  abstract = {When two people in conversation refer repeatedly to objects, they typically converge on the same (or similar) referring expressions. The repeated use of expressions by people in the same conversation has been called lexical entrainment. Lexical entrainment may emerge from the precedent of associating objects with expressions (and the perspectives they encode), or else from achieving conceptual pacts, or temporary, flexible agreements to view an object in a particular way (in which case the precedent is encoded as specific to a particular partner). We had people interact with a confederate speaker, entraining on shared perspectives (e.g., ``the shiny cylinder'') during repeated references to objects. Then either the original speaker or a new speaker used either the original expression or a new one (``the silver pipe'') to refer to the previously discussed object. Upon hearing the original expressions, addressees looked at and then touched the target objects equally quickly regardless of speaker. However, with new expressions, there was partner-specific interference: addressees were slower to look at the object when the new expression was uttered by the original speaker than when the new expression was uttered by the new speaker. This suggests that the representations in memory from which entrainment emerges do encode a partner-specific cue, leading addressees to expect that a speaker should continue to use an entrained-upon expression unless a contrast in meaning is implicated. There appears to be no such interference when a new partner uses a new expression.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/YGIEGSNG/Metzing and Brennan - 2003 - When conceptual pacts are broken Partner-specific.pdf}
}

@article{misyak2016,
  title = {Instantaneous {{Conventions}}: {{The Emergence}} of {{Flexible Communicative Signals}}},
  shorttitle = {Instantaneous {{Conventions}}},
  author = {Misyak, Jennifer and Noguchi, Takao and Chater, Nick},
  year = {2016},
  month = dec,
  journal = {Psychological Science},
  volume = {27},
  number = {12},
  pages = {1550--1561},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797616661199},
  urldate = {2025-01-24},
  abstract = {Humans can communicate even with few existing conventions in common (e.g., when they lack a shared language). We explored what makes this phenomenon possible with a nonlinguistic experimental task requiring participants to coordinate toward a common goal. We observed participants creating new communicative conventions using the most minimal possible signals. These conventions, furthermore, changed on a trial-by-trial basis in response to shared environmental and task constraints. Strikingly, as a result, signals of the same form successfully conveyed contradictory messages from trial to trial. Such behavior is evidence for the involvement of what we term joint inference, in which social interactants spontaneously infer the most sensible communicative convention in light of the common ground between them. Joint inference may help to elucidate how communicative conventions emerge instantaneously and how they are modified and reshaped into the elaborate systems of conventions involved in human communication, including natural languages.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/GIHFH7MX/Misyak et al. - 2016 - Instantaneous Conventions The Emergence of Flexible Communicative Signals.pdf}
}

@article{monroe2015,
  title = {Learning in the {{Rational Speech Acts Model}}},
  author = {Monroe, Will and Potts, Christopher},
  year = {2015},
  month = oct,
  journal = {arXiv:1510.06807 [cs]},
  eprint = {1510.06807},
  primaryclass = {cs},
  urldate = {2020-09-24},
  abstract = {The Rational Speech Acts (RSA) model treats language use as a recursive process in which probabilistic speaker and listener agents reason about each other's intentions to enrich the literal semantics of their language along broadly Gricean lines. RSA has been shown to capture many kinds of conversational implicature, but it has been criticized as an unrealistic model of speakers, and it has so far required the manual specification of a semantic lexicon, preventing its use in natural language processing applications that learn lexical knowledge from data. We address these concerns by showing how to define and optimize a trained statistical classifier that uses the intermediate agents of RSA as hidden layers of representation forming a non-linear activation function. This treatment opens up new application domains and new possibilities for learning effectively from data. We validate the model on a referential expression generation task, showing that the best performance is achieved by incorporating features approximating well-established insights about natural language generation into RSA.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/8F9ZWWRV/Monroe and Potts - 2015 - Learning in the Rational Speech Acts Model.pdf;/home/vboyce/Zotero/storage/C6RD5BSA/1510.html}
}

@article{morisseau2013,
  title = {How Do 3- and 5-Year-Olds Respond to under- and over-Informative Utterances?},
  author = {Morisseau, Tiffany and Davies, Catherine and Matthews, Danielle},
  year = {2013},
  month = dec,
  journal = {Journal of Pragmatics},
  volume = {59},
  pages = {26--39},
  issn = {03782166},
  doi = {10.1016/j.pragma.2013.03.007},
  urldate = {2025-01-07},
  abstract = {As children learn their native languages, they come to have detailed expectations about how to refer to things. These expectations and the detection of their violations are key to inference-making processes. But what do children do when their expectations are not met? Using reaction-time measures and gaze-direction monitoring in a referential communication task, we investigated whether 3- and 5-yearolds notice the infelicity of under- and over-informative utterances and then seek out further information in order to recover the speaker's intended meaning. We tested how children resolve under-informative instructions such as ``Find the orange'' when there is more than one orange in view. We also tested whether instructions such as ``Find the cat with a tail'', in a context where there is only one, normal-looking cat, would lead them to question why the speaker was over-informative and to seek out further information. Both age groups were sensitive to the ambiguous instructions. Only 5-year-olds were significantly delayed and more likely to check their interlocutor's gaze when responding to over-informative expressions. We discuss how children's spontaneous motivation to resolve violations of expectation, coupled with increased speed of linguistic processing, drives language learning.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/DU38DTZX/Morisseau et al. - 2013 - How do 3- and 5-year-olds respond to under- and over-informative utterances.pdf}
}

@article{murfitt2001,
  title = {The {{Effect}} of {{Production Variables}} in {{Monolog}} and {{Dialog}} on {{Comprehension}} by {{Novel Listeners}}},
  author = {Murfitt, Tara and McAllister, Jan},
  year = {2001},
  month = sep,
  journal = {Language and Speech},
  volume = {44},
  number = {3},
  pages = {325--350},
  publisher = {SAGE Publications Ltd},
  issn = {0023-8309},
  doi = {10.1177/00238309010440030201},
  urldate = {2023-04-07},
  abstract = {Prior research has identified a number of dimensions along which speakers modify referring expressions. The present study aimed to determine and describe the actual relationship existing between these production characteristics and corresponding measures of listener comprehension. Spoken descriptions were elicited from eight speakers during monolog and dialog conditions of the tangram task. In a subsequent listening experiment, 163 new subjects listened to the referring expressions from the speech corpus, and were asked to select, from an array of tangram figures, the one that was being described in the referring expression. Results revealed that the production variables most commonly documented by previous researchers collectively contributed to listener comprehension to a surprisingly small, but consistently significant, degree. Furthermore, the communicative context in which referring expressions were produced did not substantially influence their overall comprehensibility; instead, communicative context, as well as the individual characteristics of the speaker who produced the referring expression, appeared to affect which variables listeners found most useful when inferring what the speaker meant.},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/RL5YDJMS/Murfitt and McAllister - 2001 - The Effect of Production Variables in Monolog and .pdf}
}

@misc{murthy2022,
  title = {Shades of Confusion: {{Lexical}} Uncertainty Modulates Ad Hoc Coordination in an Interactive Communication Task},
  shorttitle = {Shades of Confusion},
  author = {Murthy, Sonia K. and Griffiths, Thomas L. and Hawkins, Robert D.},
  year = {2022},
  month = apr,
  number = {arXiv:2105.06546},
  eprint = {2105.06546},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2105.06546},
  urldate = {2022-11-09},
  abstract = {There is substantial variability in the expectations that communication partners bring into interactions, creating the potential for misunderstandings. To directly probe these gaps and our ability to overcome them, we propose a communication task based on color-concept associations. In Experiment 1, we establish several key properties of the mental representations of these expectations, or lexical priors, based on recent probabilistic theories. Associations are more variable for abstract concepts, variability is represented as uncertainty within each individual, and uncertainty enables accurate predictions about whether others are likely to share the same association. In Experiment 2, we then examine the downstream consequences of these representations for communication. Accuracy is initially low when communicating about concepts with more variable associations, but rapidly increases as participants form ad hoc conventions. Together, our findings suggest that people cope with variability by maintaining well-calibrated uncertainty about their partner and appropriately adaptable representations of their own.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/UTMWHXI2/Murthy et al. - 2022 - Shades of confusion Lexical uncertainty modulates.pdf;/home/vboyce/Zotero/storage/2WTYWAJB/2105.html}
}

@article{muttenthaler2021,
  title = {{{THINGSvision}}: {{A Python Toolbox}} for {{Streamlining}} the {{Extraction}} of {{Activations From Deep Neural Networks}}},
  shorttitle = {{{THINGSvision}}},
  author = {Muttenthaler, Lukas and Hebart, Martin N.},
  year = {2021},
  month = sep,
  journal = {Frontiers in Neuroinformatics},
  volume = {15},
  publisher = {Frontiers},
  issn = {1662-5196},
  doi = {10.3389/fninf.2021.679838},
  urldate = {2025-01-13},
  abstract = {{$<$}p{$>$}Over the past decade, deep neural network (DNN) models have received a lot of attention due to their near-human object classification performance and their excellent prediction of signals recorded from biological visual systems. To better understand the function of these networks and relate them to hypotheses about brain activity and behavior, researchers need to extract the activations to images across different DNN layers. The abundance of different DNN variants, however, can often be unwieldy, and the task of extracting DNN activations from different layers may be non-trivial and error-prone for someone without a strong computational background. Thus, researchers in the fields of cognitive science and computational neuroscience would benefit from a library or package that supports a user in the extraction task. {$<$}monospace{$>$}THINGSvision{$<$}/monospace{$>$} is a new Python module that aims at closing this gap by providing a simple and unified tool for extracting layer activations for a wide range of pretrained and randomly-initialized neural network architectures, even for users with little to no programming experience. We demonstrate the general utility of {$<$}monospace{$>$}THINGsvision{$<$}/monospace{$>$} by relating extracted DNN activations to a number of functional MRI and behavioral datasets using representational similarity analysis, which can be performed as an integral part of the toolbox. Together, {$<$}monospace{$>$}THINGSvision{$<$}/monospace{$>$} enables researchers across diverse fields to extract features in a streamlined manner for their custom image dataset, thereby improving the ease of relating DNNs, brain activity, and behavior, and improving the reproducibility of findings in these research fields.{$<$}/p{$>$}},
  langid = {english},
  keywords = {artificial intelligence,computational neuroscience,Computer Vision,Deep neural network (DNN),feature extraction,Python (programming language)},
  file = {/home/vboyce/Zotero/storage/YTLC3TZ3/Muttenthaler and Hebart - 2021 - THINGSvision A Python Toolbox for Streamlining the Extraction of Activations From Deep Neural Netwo.pdf}
}

@article{nadig2002,
  title = {Evidence of {{Perspective-Taking Constraints}} in {{Children}}'s {{On-Line Reference Resolution}}},
  author = {Nadig, Aparna S. and Sedivy, Julie C.},
  year = {2002},
  month = jul,
  journal = {Psychological Science},
  volume = {13},
  number = {4},
  pages = {329--336},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1111/j.0956-7976.2002.00460.x},
  urldate = {2024-01-16},
  abstract = {Young children's communication has often been characterized as egocentric. Some researchers claim that the processing of language involves an initial stage that relies on egocentric heuristics, even in adults. Such an account, combined with general developmental difficulties with late-stage processes, could provide an explanation for much of children's egocentric communication. However, the experimental data reported in this article do not support such an account: In an elicited-production task, 5- to 6-year-old children were found to be sensitive to their partner's perspective. Moreover, in an on-line comprehension task, they showed sensitivity to common-ground information from the initial stages of language processing. We propose that mutual knowledge is not distinct from other knowledge relevant for language processing, and exerts early effects on processing in proportion to its salience and reliability.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/P9Z7YDY9/Nadig and Sedivy - 2002 - Evidence of Perspective-Taking Constraints in Chil.pdf}
}

@article{nilsen2009,
  title = {The Relations between Children's Communicative Perspective-Taking and Executive Functioning},
  author = {Nilsen, Elizabeth S. and Graham, Susan A.},
  year = {2009},
  month = mar,
  journal = {Cognitive Psychology},
  volume = {58},
  number = {2},
  pages = {220--249},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2008.07.002},
  urldate = {2025-01-07},
  abstract = {Two experiments investigated children's communicative perspective-taking ability. In Experiment 1, 4- to 5-year-old children were tested on two referential communication tasks, as well as on measures of inhibitory control, working memory, and cognitive flexibility. Results document children's emergent use of the perspective of their speaking partner to guide their communicative behaviors in both a production and comprehension task. In Experiment 2, 3- to 4-year-old children used a speaker's perspective to guide their interpretation of instructions. In both experiments, egocentric interpretations of speaker requests were negatively correlated with children's inhibitory control skills. Results of these studies demonstrate that young children can differentiate between information that is accessible to the speaker versus privileged knowledge, and use this information to guide their communicative behaviors. Furthermore, the results suggest that children's inhibitory control skills allow them to inhibit their own perspective, enabling them to make use of their communicative partner's perspective.},
  keywords = {Cognitive development,Executive function,Inhibitory control,Perspective-taking,Pragmatic language,read,Referential communication},
  file = {/home/vboyce/Zotero/storage/K5F9YN7C/S001002850800056X.html}
}

@article{noveck2001,
  title = {When Children Are More Logical than Adults: Experimental Investigations of Scalar Implicature},
  shorttitle = {When Children Are More Logical than Adults},
  author = {Noveck, Ira A},
  year = {2001},
  month = feb,
  journal = {Cognition},
  volume = {78},
  number = {2},
  pages = {165--188},
  issn = {00100277},
  doi = {10.1016/S0010-0277(00)00114-1},
  urldate = {2020-08-31},
  abstract = {A conversational implicature is an inference that consists in attributing to a speaker an implicit meaning that goes beyond the explicit linguistic meaning of an utterance. This paper experimentally investigates scalar implicature, a paradigmatic case of implicature in which a speaker's use of a term like Some indicates that the speaker had reasons not to use a more informative one from the same scale, e.g. All; thus, Some implicates Not all. Pragmatic theorists like Grice would predict that a pragmatic interpretation is determined only after its explicit, logical meaning is incorporated (e.g. where Some means at least one). The present work aims to developmentally unpack this prediction by showing how younger, albeit competent, reasoners initially treat a relatively weak term logically before becoming aware of its pragmatic potential. Three experiments are presented. Experiment 1 presents a modal reasoning scenario offering an exhaustive set of conclusions; critical among these is participants' evaluation of a statement expressing Might be x when the context indicates that the stronger Must be x is true. The conversationally-infelicitous Might be x can be understood logically (e.g. as compatible with Must) or pragmatically (as exclusive to must). Results from five-, seven-, and nine-year-olds as well as adults revealed that a) seven-year-olds are the youngest to demonstrate modal competence overall and that; b) seven- and nine-year-olds treat the infelicitous Might logically significantly more often than adults do. Experiment 2 showed how training with the modal task can suspend the implicatures for adults. Experiment 3 provides converging evidence of the developmental pragmatic effect with the French existential quantifier Certains (Some). While linguistically-sophisticated children (eight- and ten-year-olds olds) typically treat Certains as compatible with Tous (All), adults are equivocal. These results, which are consistent with unanticipated findings in classic developmental papers, reveal a consistent ordering in which representations of weak scalar terms tend to be treated logically by young competent participants and more pragmatically by older ones. This work is also relevant to the treatment of scalar implicatures in the reasoning literature.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/AZ5PST4L/Noveck - 2001 - When children are more logical than adults experi.PDF}
}

@article{ohmer2022,
  title = {Mutual {{Exclusivity}} in {{Pragmatic Agents}}},
  author = {Ohmer, Xenia and Franke, Michael and K{\"o}nig, Peter},
  year = {2022},
  journal = {Cognitive Science},
  volume = {46},
  number = {1},
  pages = {e13069},
  issn = {1551-6709},
  doi = {10.1111/cogs.13069},
  urldate = {2023-02-10},
  abstract = {One of the great challenges in word learning is that words are typically uttered in a context with many potential referents. Children's tendency to associate novel words with novel referents, which is taken to reflect a mutual exclusivity (ME) bias, forms a useful disambiguation mechanism. We study semantic learning in pragmatic agents---combining the Rational Speech Act model with gradient-based learning---and explore the conditions under which such agents show an ME bias. This approach provides a framework for investigating a pragmatic account of the ME bias in humans but also for building artificial agents that display an ME bias. A series of analyses demonstrates striking parallels between our model and human word learning regarding several aspects relevant to the ME bias phenomenon: online inference, long-term learning, and developmental effects. By testing different implementations, we find that two components, pragmatic online inference and incremental collection of evidence for one-to-one correspondences between words and referents, play an important role in modeling the developmental trajectory of the ME bias. Finally, we outline an extension of our model to a deep neural network architecture that can process more naturalistic visual and linguistic input. Until now, in contrast to children, deep neural networks have needed indirect access to (supposed to be novel) test inputs during training to display an ME bias. Our model is the first one to do so without using this manipulation.},
  langid = {english},
  keywords = {Deep learning,Mutual exclusivity,Pragmatics,Rational Speech Act model,Reinforcement learning},
  file = {/home/vboyce/Zotero/storage/5YL6VYLC/Ohmer et al. - 2022 - Mutual Exclusivity in Pragmatic Agents.pdf;/home/vboyce/Zotero/storage/6RQMV55U/cogs.html}
}

@inproceedings{parisi2005,
  title = {Evaluating Communication Effectiveness in Team Collaboration},
  booktitle = {Ninth European Conference on Speech Communication and Technology ({{INTERSPEECH}})},
  author = {Parisi, Julie A and Brungart, Douglas S},
  year = {2005}
}

@article{pedregosa2011,
  title = {Scikit-Learn: {{Machine}} Learning in Python},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  year = {2011},
  journal = {the Journal of machine Learning research},
  volume = {12},
  pages = {2825--2830},
  publisher = {JMLR. org}
}

@article{piantadosi2012,
  title = {The Communicative Function of Ambiguity in Language},
  author = {Piantadosi, Steven T. and Tily, Harry and Gibson, Edward},
  year = {2012},
  month = mar,
  journal = {Cognition},
  volume = {122},
  number = {3},
  pages = {280--291},
  issn = {00100277},
  doi = {10.1016/j.cognition.2011.10.004},
  urldate = {2023-06-14},
  abstract = {We present a general information-theoretic argument that all efficient communication systems will be ambiguous, assuming that context is informative about meaning. We also argue that ambiguity additionally allows for greater ease of processing by allowing efficient linguistic units to be re-used. We test predictions of this theory in English, German, and Dutch. Our results and theoretical analysis suggest that ambiguity is a functional property of language that allows for greater communicative efficiency. This provides theoretical and empirical arguments against recent suggestions that core features of linguistic systems are not designed for communication.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/SXVWCGVG/Piantadosi et al. - 2012 - The communicative function of ambiguity in languag.pdf}
}

@article{piantadosi2014,
  title = {Zipf's Word Frequency Law in Natural Language: {{A}} Critical Review and Future Directions},
  shorttitle = {Zipf's Word Frequency Law in Natural Language},
  author = {Piantadosi, Steven T.},
  year = {2014},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {21},
  number = {5},
  pages = {1112--1130},
  issn = {1531-5320},
  doi = {10.3758/s13423-014-0585-6},
  urldate = {2023-07-05},
  abstract = {The frequency distribution of words has been a key object of study in statistical linguistics for the past 70 years. This distribution approximately follows a simple mathematical form known as Zipf's law. This article first shows that human language has a highly complex, reliable structure in the frequency distribution over and above this classic law, although prior data visualization methods have obscured this fact. A number of empirical phenomena related to word frequencies are then reviewed. These facts are chosen to be informative about the mechanisms giving rise to Zipf's law and are then used to evaluate many of the theoretical explanations of Zipf's law in language. No prior account straightforwardly explains all the basic facts or is supported with independent evaluation of its underlying assumptions. To make progress at understanding why language obeys Zipf's law, studies must seek evidence beyond the law itself, testing assumptions and evaluating novel predictions with new, independent data.},
  langid = {english},
  keywords = {Language,read,Statistics,Zipf's law}
}

@article{piantadosi2023,
  title = {The Algorithmic Origins of Counting},
  author = {Piantadosi, Steven T.},
  year = {2023},
  month = nov,
  journal = {Child Development},
  pages = {cdev.14031},
  issn = {0009-3920, 1467-8624},
  doi = {10.1111/cdev.14031},
  urldate = {2023-11-23},
  abstract = {The study of how children learn numbers has yielded one of the most productive research programs in cognitive development, spanning empirical and computational methods, as well as nativist and empiricist philosophies. This paper provides a tutorial on how to think computationally about learning models in a domain like number, where learners take finite data and go far beyond what they directly observe or perceive. To illustrate, this paper then outlines a model which acquires a counting procedure using observations of sets and words, extending the proposal of Piantadosi et al. (2012). This new version of the model responds to several critiques of the original work and outlines an approach which is likely appropriate for acquiring further aspects of mathematics.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/5TNTPNEX/Piantadosi - 2023 - The algorithmic origins of counting.pdf}
}

@article{pickering2004,
  title = {Toward a Mechanistic Psychology of Dialogue},
  author = {Pickering, Martin J. and Garrod, Simon},
  year = {2004},
  month = apr,
  journal = {Behavioral and Brain Sciences},
  volume = {27},
  number = {02},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X04000056},
  urldate = {2020-10-06},
  abstract = {Traditional mechanistic accounts of language processing derive almost entirely from the study of monologue. Yet, the most natural and basic form of language use is dialogue. As a result, these accounts may only offer limited theories of the mechanisms that underlie language processing in general. We propose a mechanistic account of dialogue, the interactive alignment account, and use it to derive a number of predictions about basic language processes. The account assumes that, in dialogue, the linguistic representations employed by the interlocutors become aligned at many levels, as a result of a largely automatic process. This process greatly simplifies production and comprehension in dialogue. After considering the evidence for the interactive alignment model, we concentrate on three aspects of processing that follow from it. It makes use of a simple interactive inference mechanism, enables the development of local dialogue routines that greatly simplify language processing, and explains the origins of self-monitoring in production. We consider the need for a grammatical framework that is designed to deal with language in dialogue rather than monologue, and discuss a range of implications of the account.},
  langid = {english},
  keywords = {bad i hate it,read},
  file = {/home/vboyce/Zotero/storage/SIT3MYKW/Pickering and Garrod - 2004 - Toward a mechanistic psychology of dialogue.pdf}
}

@article{potts2015,
  title = {Embedded {{Implicatures}} as {{Pragmatic Inferences}} under {{Compositional Lexical Uncertainty}}},
  author = {Potts, Christopher and Lassiter, Daniel and Levy, Roger and Frank, Michael C.},
  year = {2015},
  month = dec,
  journal = {Journal of Semantics},
  pages = {ffv012},
  issn = {0167-5133, 1477-4593},
  doi = {10.1093/jos/ffv012},
  urldate = {2020-09-24},
  abstract = {How do comprehenders reason about pragmatically ambiguous scalar terms like some in complex syntactic contexts? In many pragmatic theories of conversational implicature, local exhaustification of such terms (`only some') is predicted to be difficult or impossible if the result does not entail the literal meaning, whereas grammatical accounts predict such construals to be robustly available. Recent experimental evidence supports the salience of these local enrichments, but the grammatical theories that have been argued to account for this evidence do not provide explicit mechanisms for weighting such construals against others. We propose a probabilistic model that combines previous work on pragmatic inference under `lexical uncertainty' with a more detailed model of compositional semantics. We show that this model makes accurate predictions about new experimental data on embedded implicatures in both non-monotonic and downward-entailing semantic contexts. In addition, the model's predictions can be improved by the incorporation of neo-Gricean hypotheses about lexical alternatives. This work thus contributes to a synthesis of grammatical and probabilistic views on pragmatic inference.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/5ZM4VPB5/Potts et al. - 2015 - Embedded Implicatures as Pragmatic Inferences unde.pdf;/home/vboyce/Zotero/storage/J89UL7MR/Potts et al. - 2015 - Embedded Implicatures as Pragmatic Inferences under Compositional Lexical Uncertainty.pdf;/home/vboyce/Zotero/storage/N6L5QVMX/2563037.html}
}

@article{qing2016,
  title = {A Rational Speech-Act Model of Projective Content},
  author = {Qing, Ciyang and Goodman, Noah D and Lassiter, Daniel},
  year = {2016},
  journal = {CogSci},
  abstract = {Certain content of a linguistic construction can project when the construction is embedded in entailment-canceling environments. For example, the conclusion that John smoked in the past from the utterance John stopped smoking still holds for John didn't stop smoking, in which the original utterance is embedded under negation. There are two main approaches to account for projection phenomena. The semantic approach adds restrictions of the common ground to the conventional meaning. The pragmatic approach tries to derive projection from general conversational principles. In this paper we build a probabilistic model of language understanding in which the listener jointly infers the world state and what common ground the speaker has assumed. We take change-of-state verbs as an example and model its projective content under negation. Under certain assumptions, the model predicts the projective behavior and its interaction with the question under discussion (QUD), without any special semantic treatment of projective content.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/4J2IDARY/Qing et al. - A rational speech-act model of projective content.pdf}
}

@misc{radford2021,
  title = {Learning {{Transferable Visual Models From Natural Language Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  year = {2021},
  month = feb,
  number = {arXiv:2103.00020},
  eprint = {2103.00020},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.00020},
  urldate = {2023-04-20},
  abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/vboyce/Zotero/storage/GTCRAACV/Radford et al. - 2021 - Learning Transferable Visual Models From Natural L.pdf;/home/vboyce/Zotero/storage/A4Q8XS2F/2103.html}
}

@article{radford2022,
  title = {Robust {{Speech Recognition}} via {{Large-Scale Weak Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  year = {2022},
  abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zeroshot transfer setting without the need for any finetuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/PREQAZV2/Radford et al. - Robust Speech Recognition via Large-Scale Weak Supervision.pdf}
}

@article{rakoczy2022,
  title = {Foundations of Theory of Mind and Its Development in Early Childhood},
  author = {Rakoczy, Hannes},
  year = {2022},
  month = apr,
  journal = {Nature Reviews Psychology},
  volume = {1},
  number = {4},
  pages = {223--235},
  publisher = {Nature Publishing Group},
  issn = {2731-0574},
  doi = {10.1038/s44159-022-00037-z},
  urldate = {2024-02-07},
  abstract = {Theory of mind is the human conceptual capacity to understand other people as agents who have subjective mental states such as beliefs, desires, and intentions. It is the basis of distinctively human forms of social understanding and interaction that are essential for communication, cooperation, and culture. In this Review, I summarize the current state of research about the emergence and development of theory of mind in early childhood. I describe the typical developmental trajectory and review findings about the cognitive, linguistic, social and neural foundations of theory of mind development. Finally, I review an ongoing debate regarding whether there are different --- implicit versus explicit --- forms of theory of mind that develop independently, and conclude by providing an outlook on future challenges and perspectives for research in this area.},
  copyright = {2022 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Human behaviour,Psychology,read},
  file = {/home/vboyce/Zotero/storage/2VWAYRIF/Rakoczy - 2022 - Foundations of theory of mind and its development .pdf}
}

@inproceedings{reder1988,
  title = {The Communicative Economy of the Workgroup: {{Multi-channel}} Genres of Communication},
  booktitle = {Proceedings of the 1988 {{ACM}} Conference on {{Computer-supported}} Cooperative Work},
  author = {Reder, Stephen and Schwab, Robert G},
  year = {1988},
  pages = {354--368}
}

@misc{reimers2019,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  month = aug,
  number = {arXiv:1908.10084},
  eprint = {1908.10084},
  primaryclass = {cs},
  institution = {arXiv},
  doi = {10.48550/arXiv.1908.10084},
  urldate = {2022-06-06},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/ILGFYQCC/Reimers and Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf;/home/vboyce/Zotero/storage/NB9T7L66/1908.html}
}

@article{rogers2013,
  title = {Audience {{Design}} through {{Social Interaction}} during {{Group Discussion}}},
  author = {Rogers, Shane L. and Fay, Nicolas and Maybery, Murray},
  year = {2013},
  month = feb,
  journal = {PLOS ONE},
  volume = {8},
  number = {2},
  pages = {e57211},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0057211},
  urldate = {2023-07-12},
  abstract = {This paper contrasts two accounts of audience design during multiparty communication: audience design as a strategic individual-level message adjustment or as a non-strategic interaction-level message adjustment. Using a non-interactive communication task, Experiment 1 showed that people distinguish between messages designed for oneself and messages designed for another person; consistent with strategic message design, messages designed for another person/s were longer (number of words) than those designed for oneself. However, audience size did not affect message length (messages designed for different sized audiences were similar in length). Using an interactive communication task Experiment 2 showed that as group size increased so too did communicative effort (number of words exchanged between interlocutors). Consistent with a non-strategic account, as group members were added more social interaction was necessary to coordinate the group's collective situation model. Experiment 3 validates and extends the production measures used in Experiment 1 and 2 using a comprehension task. Taken together, our results indicate that audience design arises as a non-strategic outcome of social interaction during group discussion.},
  langid = {english},
  keywords = {Communications,Computer games,important,Language,read,Social communication,Speech,Syntax,Undergraduates,useful,Verbal communication},
  file = {/home/vboyce/Zotero/storage/8QRG4VEJ/Rogers et al. - 2013 - Audience Design through Social Interaction during .pdf}
}

@article{rubio-fernandez2021,
  title = {Speakers and Listeners Exploit Word Order for Communicative Efficiency: {{A}} Cross-Linguistic Investigation},
  shorttitle = {Speakers and Listeners Exploit Word Order for Communicative Efficiency},
  author = {{Rubio-Fernandez}, Paula and Mollica, Francis and {Jara-Ettinger}, Julian},
  year = {2021},
  journal = {Journal of Experimental Psychology: General},
  volume = {150},
  pages = {583--594},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2222},
  doi = {10.1037/xge0000963},
  abstract = {Pragmatic theories and computational models of reference must account for people's frequent use of redundant color adjectives (e.g., referring to a single triangle as ``the blue triangle''). The standard pragmatic view holds that the informativity of a referential expression depends on pragmatic contrast: Color adjectives should be used to contrast competitors of the same kind to preempt an ambiguity (e.g., between several triangles of different colors), otherwise they are redundant. Here we propose an alternative to the standard view, the incremental efficiency hypothesis, according to which the efficiency of a referential expression must be calculated incrementally over the entire visual context. This is the first theoretical account of referential efficiency that is sensitive to the incrementality of language processing, making different cross-linguistic predictions depending on word order. Experiment 1 confirmed that English speakers produced more redundant color adjectives (e.g., ``the blue triangle'') than Spanish speakers (e.g., ``el tri{\'a}ngulo azul''), but both language groups used more redundant color adjectives in denser displays where it would be more efficient. In Experiments 2A and 2B, we used eye tracking to show that pragmatic contrast is not a processing constraint. Instead, incrementality and efficiency determine that English listeners establish color contrast across categories (BLUE SHAPES {$>$} TRIANGULAR ONE), whereas Spanish listeners establish color contrast within a category (TRIANGLES {$>$} BLUE ONE). Spanish listeners, however, reversed their visual search strategy when tested in English immediately after. Our results show that speakers and listeners of different languages exploit word order to increase communicative efficiency. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Adjectives,Audiences,Color Contrast,Color Perception,Communication,Linguistics,Pragmatics,read,Visual Search,Visual Tracking,Word Frequency},
  file = {/home/vboyce/Zotero/storage/SHVDRAQW/Rubio-Fernandez et al. - 2021 - Speakers and listeners exploit word order for comm.pdf}
}

@article{rubio-fernandez2024,
  title = {Tracking Minds in Communication},
  author = {{Rubio-Fernandez}, Paula and Berke, Marlene D. and {Jara-Ettinger}, Julian},
  year = {2024},
  month = dec,
  journal = {Trends in Cognitive Sciences},
  pages = {S1364661324003127},
  issn = {13646613},
  doi = {10.1016/j.tics.2024.11.005},
  urldate = {2025-01-02},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/GU8MRTZZ/Rubio-Fernandez et al. - 2024 - Tracking minds in communication.pdf}
}

@article{sanjuan2015,
  title = {A {{New Perspective}} on {{Children}}'s {{Communicative Perspective Taking}}: {{When}} and {{How Do Children Use Perspective Inferences}} to {{Inform Their Comprehension}} of {{Spoken Language}}?},
  shorttitle = {A {{New Perspective}} on {{Children}}'s {{Communicative Perspective Taking}}},
  author = {San Juan, Valerie and Khu, Melanie and Graham, Susan A.},
  year = {2015},
  journal = {Child Development Perspectives},
  volume = {9},
  number = {4},
  pages = {245--249},
  issn = {1750-8606},
  doi = {10.1111/cdep.12141},
  urldate = {2024-06-18},
  abstract = {Successful communication often requires a listener to reason about a speaker's perspective to make inferences about communicative intent. Although children can use perspective reasoning to influence their interpretation of spoken utterances, when and how children integrate perspective reasoning with language comprehension remain unclear. These questions are central to theoretical debates in language processing and have led to competing accounts of communicative perspective taking: early versus late integration. In this article, we examine how developmental evidence addresses the predictions of each account. Specifically, we review evidence to determine whether children can rapidly integrate perspective inferences when processing spoken language while central abilities (i.e., executive function and theory of mind) are still emerging.},
  langid = {english},
  keywords = {perspective taking,possibly useful for citation following,read,referential communication},
  file = {/home/vboyce/Zotero/storage/PLV9IBYW/San Juan et al. - 2015 - A New Perspective on Children's Communicative Pers.pdf;/home/vboyce/Zotero/storage/3FAH4HWX/cdep.html}
}

@article{schober1989,
  title = {Understanding by Addressees and Overhearers},
  author = {Schober, Michael F and Clark, Herbert H},
  year = {1989},
  month = apr,
  journal = {Cognitive Psychology},
  volume = {21},
  number = {2},
  pages = {211--232},
  issn = {00100285},
  doi = {10.1016/0010-0285(89)90008-X},
  urldate = {2022-02-01},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/ZDTA9P82/Schober and Clark - 1989 - Understanding by addressees and overhearers.pdf}
}

@article{schuster2020,
  title = {I Know What You're Probably Going to Say: {{Listener}} Adaptation to Variable Use of Uncertainty Expressions},
  shorttitle = {I Know What You're Probably Going to Say},
  author = {Schuster, Sebastian and Degen, Judith},
  year = {2020},
  month = oct,
  journal = {Cognition},
  volume = {203},
  pages = {104285},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2020.104285},
  urldate = {2025-01-27},
  abstract = {Pragmatic theories of utterance interpretation share the assumption that listeners reason about alternative utterances that a speaker could have produced, but didn't. For such reasoning to be successful, listeners must have precise expectations about a speaker's production choices. This is at odds with the considerable variability across speakers that exists at all levels of linguistic representation. This tension can be reconciled by listeners adapting to the statistics of individual speakers. While linguistic adaptation is increasingly widely attested, semantic/pragmatic adaptation is underexplored. Moreover, what kind of representations listeners update during semantic/pragmatic adaptation -- estimates of the speaker's lexicon, or estimates of the speaker's utterance preferences -- remains poorly understood. In this work, we investigate semantic/pragmatic adaptation in the domain of uncertainty expressions like might and probably. In a series of web-based experiments, we find 1) that listeners vary in their expectations about a generic speaker's use of uncertainty expressions; 2) that listeners rapidly update their expectations about the use of uncertainty expressions after brief exposure to a speaker with a specific usage of uncertainty expressions; and 3) that listeners' interpretations of uncertainty expressions change after being exposed to a specific speaker. We present a novel computational model of semantic/pragmatic adaptation based on Bayesian belief updating and show, through a series of model comparisons, that semantic/pragmatic adaptation is best captured by listeners updating their beliefs both about the speaker's lexicon and their utterance preferences. This work has implications for both semantic theories of uncertainty expressions and psycholinguistic theories of adaptation: it highlights the need for dynamic semantic representations and suggests that listeners integrate their general linguistic knowledge with speaker-specific experiences to arrive at more precise interpretations.},
  keywords = {Adaptation,Bayesian cognitive modeling,Experimental pragmatics,Language comprehension,read,Uncertainty expressions},
  file = {/home/vboyce/Zotero/storage/H9CCVLU7/Schuster and Degen - 2020 - I know what you're probably going to say Listener adaptation to variable use of uncertainty express.pdf;/home/vboyce/Zotero/storage/NG34E5Q2/S0010027720301049.html}
}

@article{seaman1997,
  title = {Communication and Organization in Software Development: {{An}} Empirical Study},
  author = {Seaman, Carolyn B and Basili, Victor R},
  year = {1997},
  journal = {IBM Systems Journal},
  volume = {36},
  number = {4},
  pages = {550--563},
  publisher = {IBM}
}

@article{snell,
  title = {Do {{Love You Me}}? {{Failure}} to {{Notice Word Transpositions}} Is {{Induced}} by {{Parallel Word Processing}}},
  shorttitle = {Do {{Love You Me}}?},
  author = {Snell, Joshua and Melo, Alline Nogueira},
  journal = {Journal of Cognition},
  volume = {7},
  number = {1},
  pages = {21},
  issn = {2514-4820},
  doi = {10.5334/joc.335},
  urldate = {2024-02-08},
  abstract = {Recent research has shown that readers may to fail notice word transpositions during reading (e.g., the transposition of ``fail'' and ``to'' in this sentence). Although this transposed word (TW) phenomenon was initially taken as evidence that readers process multiple words in parallel, several studies now show that TW-effects may also occur when words are presented one-by-one. Critically however, in the majority of studies TW-effects are weaker in serial presentation. Here we argue that while word position coding may to some extent proceed post-lexically (allowing TW-effects to occur despite seeing words one-by-one), stronger TW-effects in parallel presentation nonetheless evidence a degree of parallel word processing. We additionally report an experiment wherein a sample of Dutch participants (N = 34) made grammaticality judgments about 4-word TW sentences (e.g., `the was man here', `the went dog away') and ungrammatical control sentences (`the man dog here', `the was went away'), whereby the four words were presented either serially or in parallel. Ungrammaticality was decidedly more difficult to notice in the TW condition, but only when words were presented in parallel. No effects were observed in the serial presentation whatsoever. The present results bolster the notion that word order is encoded with a degree of flexibility, and further provide straightforward evidence for parallel word processing during reading.},
  pmcid = {PMC10836188},
  pmid = {38312941},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6SLVR5N3/Snell and Melo - Do Love You Me Failure to Notice Word Transpositi.pdf}
}

@article{swaab2012,
  title = {The Communication Orientation Model: {{Explaining}} the Diverse Effects of Sight, Sound, and Synchronicity on Negotiation and Group Decision-Making Outcomes},
  author = {Swaab, Roderick I and Galinsky, Adam D and Medvec, Victoria and Diermeier, Daniel A},
  year = {2012},
  journal = {Personality and Social Psychology Review},
  volume = {16},
  number = {1},
  pages = {25--53},
  publisher = {Sage Publications Sage CA: Los Angeles, CA}
}

@article{tanenhaus1995,
  title = {Integration of Visual and Linguistic Information in Spoken Language Comprehension},
  author = {Tanenhaus, M. and {Spivey-Knowlton}, M. and Eberhard, K. and Sedivy, J.},
  year = {1995},
  month = jun,
  journal = {Science},
  volume = {268},
  number = {5217},
  pages = {1632--1634},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.7777863},
  urldate = {2020-09-15},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6BKS4LSL/Tanenhaus et al. - 1995 - Integration of visual and linguistic information i.pdf}
}

@book{tannen2005,
  title = {Conversational Style: {{Analyzing}} Talk among Friends},
  author = {Tannen, Deborah},
  year = {2005},
  publisher = {Oxford University Press}
}

@article{tolins2016,
  title = {Overhearers {{Use Addressee Backchannels}} in {{Dialog Comprehension}}},
  author = {Tolins, Jackson and Fox Tree, Jean E.},
  year = {2016},
  month = aug,
  journal = {Cognitive Science},
  volume = {40},
  number = {6},
  pages = {1412--1434},
  issn = {03640213},
  doi = {10.1111/cogs.12278},
  urldate = {2022-02-01},
  abstract = {Observing others in conversation is a common format for comprehending language, yet little work has been done to understand dialogue comprehension. We tested whether overhearers use addressee backchannels as predictive cues for how to integrate information across speaker turns during comprehension of spontaneously produced collaborative narration. In Experiment 1, words that followed specific backchannels (e.g. really, oh) were recognized more slowly than words that followed either generic backchannels (e.g. uh huh, mhm) or pauses. In Experiment 2, we found that when the turn after the backchannel was a continuation of the narrative, specific backchannels prompted the fastest verification of prior information. When the turn after was an elaboration, they prompted the slowest, indicating that overhearers took specific backchannels as cues to integrate preceding talk with subsequent talk. These findings demonstrate that overhearers capitalize on the predictive relationship between backchannels and the development of speakers' talk, coordinating information across conversational roles.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/93U3GRYT/Tolins and Fox Tree - 2016 - Overhearers Use Addressee Backchannels in Dialog C.pdf}
}

@book{tomasello2008,
  title = {Origins of Human Communication},
  author = {Tomasello, Michael},
  year = {2008},
  series = {The {{Jean Nicod}} Lectures},
  publisher = {MIT press},
  address = {Cambridge (Mass.)},
  isbn = {978-0-262-20177-3},
  langid = {english},
  keywords = {read,useful},
  file = {/home/vboyce/Zotero/storage/JC5D5SZ5/Tomasello - 2008 - Origins of human communication.pdf}
}

@incollection{traum2004,
  ids = {traumIssuesMultipartyDialogues2004a},
  title = {Issues in {{Multiparty Dialogues}}},
  booktitle = {Advances in {{Agent Communication}}},
  author = {Traum, David},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Dignum, Frank},
  year = {2004},
  volume = {2922},
  pages = {201--211},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-24608-4_12},
  urldate = {2022-02-01},
  abstract = {Thi5 article exanunes some of the issues in representation of, procc{\textasciitilde}{\textasciitilde}ing, and},
  isbn = {978-3-540-20769-6 978-3-540-24608-4},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/6JC5JUWX/Traum - 2004 - Issues in Multiparty Dialogues.pdf}
}

@article{turan-kucuk2024,
  title = {Three-Year-Olds' Ability to Plan for Mutually Exclusive Future Possibilities Is Limited Primarily by Their Representations of Possible Plans, Not Possible Events},
  author = {{Turan-K{\"u}{\c c}{\"u}k}, Esra Nur and Kibbe, Melissa M.},
  year = {2024},
  month = mar,
  journal = {Cognition},
  volume = {244},
  pages = {105712},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2023.105712},
  urldate = {2025-01-21},
  abstract = {The ability to prepare for mutually exclusive possible events in the future is essential for everyday decision making. Previous studies have suggested that this ability develops between the ages of 3 and 5~years, and in young children is primarily limited by the ability to represent the set of possible outcomes of an event as ``possible''. We tested an alternative hypothesis that this ability may be limited by the ability to represent the set of possible actions that could be taken to prepare for those possible outcomes. We adapted the inverted y-shaped tube task of Redshaw and Suddendorf (2016), in which children are asked to catch a marble that is dropped into the top of the tube and can emerge from either the left or right branch of the tube. While 4-year-olds typically place their hands under both openings to catch the marble, preparing for both possible outcomes (optimal action), 3-year-olds often cover only one opening, preparing for only one possible outcome (suboptimal action). In three Experiments, we asked whether first showing children the set of possible actions that could be taken on the tube would enable them to recognize the optimal action that should be used to catch the marble (Experiments 1 and 3, total n~=~99 US 3- and 4-year-olds) and enable them to use the optimal action themselves (Experiment 2, n~=~96 US 3- and 4-year-olds). We found that 3- and 4-year-olds performed similarly when they were given the opportunity to observe the set of possible actions beforehand. These findings suggest that 3-year-olds' competence at representing mutually exclusive possibilities may be masked by their developing ability to represent and deploy plans to act on these possibilities.},
  keywords = {Cognitive development,Future-oriented thinking,Modal reasoning,Planning,Possibility,read},
  file = {/home/vboyce/Zotero/storage/F8MPAHWA/accepted TuranKucuk Kibbe Cognition.pdf;/home/vboyce/Zotero/storage/AMGCB9VT/S0010027723003463.html}
}

@article{turner2021,
  title = {Audience {{Design}} in {{Collaborative Dialogue}} between {{Teachers}} and {{Students}}},
  author = {Turner, Christina and Knutsen, Dominique},
  year = {2021},
  month = apr,
  journal = {Discourse Processes},
  pages = {1--23},
  issn = {0163-853X, 1532-6950},
  doi = {10.1080/0163853X.2021.1904768},
  urldate = {2021-06-03},
  abstract = {When two people interact, reference presentation is shaped with the inten\- tion of supporting addressee understanding, allowing for ease of accep\- tance, thus minimizing overall collaborative effort. To date, analysis of such audience design has focused largely on adult--adult or adult--child interaction but seldom on adult--teenager interaction, including teacher--student inter\- action. An experiment was conducted in a British school in which teachers and students interacted to establish a reference for abstract tangram figures. Teachers were able to account for the students' increased ability to behave in a more adult-like collaborative way with dialogue features similar to those in adult--adult contexts. Set apart was dialogue with young students, where teachers continued to guide the interaction by producing lengthier descrip\- tions and by encouraging participation. Dialogue with young students differs from that with other teachers in terms of the amount of effort put into the interaction and in how this effort is distributed and shared among dialogue partners.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/ZQ7NQLRF/Turner and Knutsen - 2021 - Audience Design in Collaborative Dialogue between .pdf}
}

@article{vandebraak2021,
  title = {Computational Challenges in Explaining Communication: {{How}} Deep the Rabbit Hole Goes},
  shorttitle = {Computational Challenges in Explaining Communication},
  author = {{van de Braak}, Laura and Dingemanse, Mark and Toni, Ivan and {van Rooij}, Iris and Blokpoel, Mark},
  year = {2021},
  month = may,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/3wh5g},
  urldate = {2021-05-25}
}

@article{weber2003,
  title = {Cultural {{Conflict}} and {{Merger Failure}}: {{An Experimental Approach}}},
  author = {Weber, Roberto A and Camerer, Colin F},
  year = {2003},
  journal = {Management Science},
  volume = {49},
  number = {4},
  pages = {16},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/J4CX7UN3/Weber and Camerer - 2003 - Cultural Conﬂict and Merger Failure An Experiment.pdf}
}

@article{white2020,
  title = {Learning to Refer Informatively by Amortizing Pragmatic Reasoning},
  author = {White, Julia and Mu, Jesse and Goodman, Noah D.},
  year = {2020},
  month = may,
  journal = {arXiv:2006.00418 [cs]},
  eprint = {2006.00418},
  primaryclass = {cs},
  urldate = {2021-11-06},
  abstract = {A hallmark of human language is the ability to effectively and efficiently convey contextually relevant information. One theory for how humans reason about language is presented in the Rational Speech Acts (RSA) framework, which captures pragmatic phenomena via a process of recursive social reasoning (Goodman \& Frank, 2016). However, RSA represents ideal reasoning in an unconstrained setting. We explore the idea that speakers might learn to amortize the cost of RSA computation over time by directly optimizing for successful communication with an internal listener model. In simulations with grounded neural speakers and listeners across two communication game datasets representing synthetic and human-generated data, we find that our amortized model is able to quickly generate language that is effective and concise across a range of contexts, without the need for explicit pragmatic reasoning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,read},
  file = {/home/vboyce/Zotero/storage/5D8FCPM2/White et al. - 2020 - Learning to refer informatively by amortizing prag.pdf;/home/vboyce/Zotero/storage/KG993L3T/White et al. - 2020 - Learning to refer informatively by amortizing prag.pdf;/home/vboyce/Zotero/storage/Q9PD6PXW/2006.html}
}

@article{wilkes-gibbs1992,
  title = {Coordinating Beliefs in Conversation},
  author = {{Wilkes-Gibbs}, Deanna and Clark, H.},
  year = {1992},
  journal = {Journal of Memory and Language},
  pages = {183--194},
  abstract = {We show that participants in conversation develop beliefs about shared information that others do not. So-called directors talked with two partners in succession (A and B) to arrange unusual figures. Directors went from long, indefinite descriptions of the figures to short, definite references as common ground was built up with A. When B had been a silent side participant in the fast conversation, directors continued to use short references when they changed partners. References became less efftcient when B had not been a participant-even when B had heard the first conversation and seen the figures. When B had only heard the fast conversation, he or she was treated much the same as a completely naive partner. Apparently, conversation provides preferred evidence for coordinating beliefs about shared information. o 1992 ACZ\&{\textasciitilde}{\textasciitilde}C press, IN. In conversation, speakers collaborate with their partners in making references. In an earlier paper (Clark BL Wilkes-Gibbs, 1986), we proposed that when a speaker wants to refer to an object, it is not enough for her to utter a noun phrase such as the Allen wrench. She and her partner are also responsible for establishing that he has understood her as intended. What they do, therefore, is try to reach the mutual belief that he has understood her reference well enough for current purposes. They collaborate to reach this belief; she looks for reliable evidence of his understanding and he tries to provide it. In the process, he may offer alternative phrasing and ask for repeats or repairs (you mean the small metal thing shaped like an L?); she may offer more information and ask for confirmation. Predictions of the collaborative theory, as we will call it, have been confirmed for repeated references to objects (Clark \& Wilkes-Gibbs, 1986), for partners with disparate goals (Wilkes-Gibbs, 1986), and dis-Send correspondence and reprint requests to D.},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/QNRMAUJI/Clark - 1992 - Coordinating beliefs in conversation.pdf}
}

@book{wittgenstein1953,
  title = {Philosophical Investigations},
  author = {Wittgenstein, Ludwig},
  year = {1953},
  publisher = {Wiley-Blackwell},
  address = {New York, NY, USA}
}

@article{wu2007,
  title = {The {{Effect}} of {{Information Overlap}} on {{Communication Effectiveness}}},
  author = {Wu, Shali and Keysar, Boaz},
  year = {2007},
  journal = {Cognitive Science},
  volume = {31},
  number = {1},
  pages = {169--181},
  issn = {1551-6709},
  doi = {10.1080/03640210709336989},
  urldate = {2021-05-11},
  abstract = {It makes sense that the more information people share, the better they communicate. To evaluate the effect of knowledge overlap on the effectiveness of communication, participants played a communication game where the ``director'' identified objects to the ``addressee''. Pairs either shared information about most objects' names (high overlap), or about the minority of objects' names (low overlap). We found that high-overlap directors tended to use more names than low overlap directors. High overlap directors also used more names with objects whose names only they knew, thereby confusing their addressees more often than low-overlap directors. We conclude that while sharing more knowledge can be beneficial to communication overall, it can cause communication to be locally ineffective. Sharing more information reduces communication effectiveness precisely when there is an opportunity to inform---when people communicate information only they themselves know.},
  langid = {english},
  keywords = {Communication effectiveness,Information,Language use,read,Reference,Satisficing},
  file = {/home/vboyce/Zotero/storage/BK4CDQXY/Wu and Keysar - 2007 - The Effect of Information Overlap on Communication.pdf;/home/vboyce/Zotero/storage/BCHLXVZW/03640210709336989.html}
}

@article{yarkoni2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  month = nov,
  journal = {Perspectives on Psychological Science: A Journal of the Association for Psychological Science},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  issn = {1745-6924},
  doi = {10.1177/1745691617693393},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  pmcid = {PMC6603289},
  pmid = {28841086},
  keywords = {explanation,Humans,machine learning,Machine Learning,prediction,Psychology,read,useful},
  file = {/home/vboyce/Zotero/storage/TN388IJM/Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf}
}

@article{yoon2012,
  title = {Influence of Perspective and Goals on Reference Production in Conversation},
  author = {Yoon, Si On and Koh, Sungryong and {Brown-Schmidt}, Sarah},
  year = {2012},
  month = aug,
  journal = {Psychonomic Bulletin \& Review},
  volume = {19},
  number = {4},
  pages = {699--707},
  issn = {1531-5320},
  doi = {10.3758/s13423-012-0262-6},
  urldate = {2023-08-31},
  abstract = {We examined the extent to which speakers take into consideration the addressee's perspective in language production. Previous research on this process had revealed clear deficits (Horton \& Keysar, Cognition 59:91--117, 1996; Wardlow Lane \& Ferreira, Journal of Experimental Psychology: Learning, Memory, and Cognition 34:1466--1481, 2008). Here, we evaluated a new hypothesis---that the relevance of the addressee's perspective depends on the speaker's goals. In two experiments, Korean speakers described a target object in situations in which the perspective status of a competitor object (e.g., a large plate when describing a smaller plate) was manipulated. In Experiment 1, we examined whether speakers would use scalar-modified expressions even when the competitor was hidden from the addressee. The results demonstrated that information from both the speaker's and the addressee's perspectives influenced production. In Experiment 2, we examined whether utterance goals modulate this process. The results indicated that when a speaker makes a request, the addressee's perspective has a stronger influence than it does when the speaker informs the addressee. These results suggest that privileged knowledge does shape language use, but crucially, that the degree to which the addressee's perspective is considered is shaped by the relevance of the addressee's perspective to the utterance goals.},
  langid = {english},
  keywords = {Language production,Perspective,Psycholinguistics,read,Referential expression,Utterance goal},
  file = {/home/vboyce/Zotero/storage/YR5LWXXI/Yoon et al. - 2012 - Influence of perspective and goals on reference pr.pdf}
}

@article{yoon2014,
  title = {Adjusting Conceptual Pacts in Three-Party Conversation.},
  author = {Yoon, Si On and {Brown-Schmidt}, Sarah},
  year = {2014},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {40},
  number = {4},
  pages = {919--937},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0036161},
  urldate = {2020-10-02},
  abstract = {During conversation, partners develop representations of jointly known information---the common ground---and use this knowledge to guide subsequent linguistic exchanges. Extensive research on 2-party conversation has offered key insights into this process, in particular, its partner-specificity: Common ground that is shared with 1 partner is not always assumed to be shared with other partners. Conversation often involves multiple pairs of individuals who differ in common ground. Yet, little is known about common ground processes in multi-party conversation. Here, we take a 1st step toward understanding this problem by examining situations in which simple dyadic representations of common ground might cause difficulty---situations in which dialogue partners develop shared labels (entrained terms), and then a 3rd (na{\"i}ve) party joins the conversation. Experiment 1 examined unscripted, task-based conversation in which 2 partners entrained on terms. At test, speakers referenced game-pieces in a dialogue with their partner, or in a 3-party conversation including a new, na{\"i}ve listener. Speakers were sensitive to the 3rd party, using longer, disfluent expressions when additionally addressing the new partner. By contrast, analysis of listener eye-fixations did not suggest sensitivity. Experiment 2 provided a stronger test of sensitivity and revealed that listeners do cancel expectations for terms that had been entrained before when a 3rd, na{\"i}ve party joins the conversation. These findings shed light on the mechanisms underlying common ground, showing that rather than a unitary construct, common ground is flexibly adapted to the needs of a na{\"i}ve 3rd party.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/TDUGUABF/Yoon and Brown-Schmidt - 2014 - Adjusting conceptual pacts in three-party conversa.pdf}
}

@article{yoon2018,
  title = {Aim {{Low}}: {{Mechanisms}} of {{Audience Design}} in {{Multiparty Conversation}}},
  shorttitle = {Aim {{Low}}},
  author = {Yoon, Si On and {Brown-Schmidt}, Sarah},
  year = {2018},
  month = oct,
  journal = {Discourse Processes},
  volume = {55},
  number = {7},
  pages = {566--592},
  issn = {0163-853X, 1532-6950},
  doi = {10.1080/0163853X.2017.1286225},
  urldate = {2022-02-01},
  abstract = {It is well established in studies of two-party conversation that conversational partners jointly establish brief labels for repeatedly mentioned entities. When speaking to a new partner who is unfamiliar with the labels, speakers use longer expressions to facilitate understanding. How this process of audience design scales up to multiparty conversation, where individuals differ in mutual knowledge, is unknown. Here we propose, and test, three potential hypotheses regarding how speakers design referring expressions in threeparty conversation. Participants completed a referential communication task in groups of three in which one participant, the Director, gave instructions to two Matchers who differed in their knowledge of referential labels. Directors flexibly alternated between partner-specific representations of common ground (CG), producing longer descriptions for low-CG than for high-CG partners. When addressing multiple parties at once, speakers tailored descriptions for the least knowledgeable person. These findings shed light on the mechanisms that support audience design in multiparty conversation: Audience design begins with access to distinct representations of common ground held with the intended addressee or addressees. These distinct representations support an audience design process in which utterances are tailored to accommodate the least knowledgeable addressee in a group.},
  langid = {english},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/WRJR6NWA/Yoon and Brown-Schmidt - 2018 - Aim Low Mechanisms of Audience Design in Multipar.pdf}
}

@misc{yoon2018a,
  type = {Preprint},
  ids = {yoonPoliteSpeechEmerges2018a},
  title = {Polite Speech Emerges from Competing Social Goals},
  author = {Yoon, Erica J. and Frank, Michael C. and Tessler, Michael Henry and Goodman, Noah D.},
  year = {2018},
  month = dec,
  institution = {PsyArXiv},
  doi = {10.31234/osf.io/67ne8},
  urldate = {2020-09-24},
  abstract = {Language is a remarkably efficient tool for transmitting information. Yet human speakers make statements that are inefficient, imprecise, or even contrary to their own beliefs, all in the service of being polite. What rational machinery underlies polite language use? Here, we show that polite speech emerges from the competition of three communicative goals: to convey information, to be kind, and to present oneself in a good light. We formalize this goal tradeoff using a probabilistic model of utterance production, which predicts human utterance choices in socially-sensitive situations with high quantitative accuracy, and we show that our full model is superior to its variants with subsets of the three goals. This utility-theoretic approach to speech acts takes a step towards explaining the richness and subtlety of social language use.},
  langid = {english},
  keywords = {Cognitive Psychology,communicative goals,computational modeling,Language,politeness,pragmatics,read,Social and Behavioral Sciences},
  file = {/home/vboyce/Zotero/storage/94ZTRJWG/Yoon et al. - 2018 - Polite speech emerges from competing social goals.pdf;/home/vboyce/Zotero/storage/B7BGC22A/Yoon et al. - 2018 - Polite speech emerges from competing social goals.pdf}
}

@article{yoon2019,
  title = {Audience {{Design}} in {{Multiparty Conversation}}},
  author = {Yoon, Si On and Brown-Schmidt, Sarah},
  year = {2019},
  journal = {Cognitive Science},
  volume = {43},
  number = {8},
  pages = {e12774},
  issn = {1551-6709},
  doi = {10.1111/cogs.12774},
  urldate = {2020-10-01},
  abstract = {How do speakers design what they say in order to communicate effectively with groups of addressees who vary in their background knowledge of the topic at hand? Prior findings indicate that when a speaker addresses a pair of listeners with discrepant knowledge, that speakers Aim Low, designing their utterances for the least knowledgeable of the two addressees. Here, we test the hypothesis that speakers will depart from an Aim Low approach in order to efficiently communicate with larger groups of interacting partners. Further, we ask whether the cognitive demands of tracking multiple conversational partners' perspectives places limitations on successful audience design. We find that speakers can successfully track information about what up to four of their partners do and do not know in conversation. When addressing groups of 3--4 addressees at once, speakers design language based on the combined knowledge of the group. These findings point to an audience design process that simultaneously represents the perspectives of multiple other individuals and combines these representations in order to design utterances that strike a balance between the different needs of the individuals within the group.},
  langid = {english},
  keywords = {Audience design,Common ground,Language production,Multiparty conversation,read,Reference},
  file = {/home/vboyce/Zotero/storage/5SDQYR8M/Yoon and Brown‐Schmidt - 2019 - Audience Design in Multiparty Conversation.pdf;/home/vboyce/Zotero/storage/GKPVB9H4/Yoon and Brown‐Schmidt - 2019 - Audience Design in Multiparty Conversation.pdf;/home/vboyce/Zotero/storage/I9VCZPQ8/cogs.html}
}

@article{yoon2019a,
  title = {Contextual {{Integration}} in {{Multiparty Audience Design}}},
  author = {Yoon, Si On and Brown-Schmidt, Sarah},
  year = {2019},
  journal = {Cognitive Science},
  volume = {43},
  number = {12},
  pages = {e12807},
  issn = {1551-6709},
  doi = {10.1111/cogs.12807},
  urldate = {2020-10-01},
  abstract = {Communicating with multiple addressees poses a problem for speakers: Each addressee necessarily comes to the conversation with a different perspective---different knowledge, different beliefs, and a distinct physical context. Despite the ubiquity of multiparty conversation in everyday life, little is known about the processes by which speakers design language in multiparty conversation. While prior evidence demonstrates that speakers design utterances to accommodate addressee knowledge in multiparty conversation, it is unknown if and how speakers encode and combine different types of perspective information. Here we test whether speakers encode the perspective of multiple addressees, and then simultaneously consider their knowledge and physical context during referential design in a three-party conversation. Analyses of referential form---expression length, disfluency, and elaboration rate---in an interactive multiparty conversation demonstrate that speakers do take into consideration both addressee knowledge and physical context when designing utterances, consistent with a knowledge-scene integration view. These findings point to an audience design process that takes as input multiple types of representations about the perspectives of multiple addressees, and that bases the informational content of the to-be-designed utterance on a combination of the perspectives of the intended addressees.},
  langid = {english},
  keywords = {Audience design,Common ground,Language production,Multiparty conversation,read,Reference},
  file = {/home/vboyce/Zotero/storage/57SS9DIE/Yoon and Brown‐Schmidt - 2019 - Contextual Integration in Multiparty Audience Desi.pdf;/home/vboyce/Zotero/storage/NIFUXRFV/Yoon and Brown‐Schmidt - 2019 - Contextual Integration in Multiparty Audience Desi.pdf;/home/vboyce/Zotero/storage/XETUIWQ3/cogs.html}
}

@article{yoon2023,
  title = {Keeping Track of Who Knows What in Multiparty Conversation despite Severe Memory Impairment},
  author = {Yoon, Si On and Duff, Melissa C. and {Brown-Schmidt}, Sarah},
  year = {2023},
  month = dec,
  journal = {Neuropsychologia},
  pages = {108780},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2023.108780},
  urldate = {2024-01-02},
  abstract = {Language use has long been understood to be tailored to the intended addressee, a process termed audience design. Audience design is reflected in multiple aspects of language use, including adjustments based on the addressee's knowledge about the topic at hand. In group settings, audience design depends on representations of multiple individuals, each of whom may have different knowledge about the conversational topic. A central question, then, concerns how these representations are encoded and retrieved in multiparty conversation where successful conversation requires keeping track of who knows what. In the present research, we probe the biological memory systems that are involved in this process of multiparty audience design. We present the results of two experiments that compare language use in persons with bilateral hippocampal damage and severe declarative memory impairment (amnesia), and demographically matched neurotypical comparison participants. Participants played a game in which they discussed abstract images with one partner in conversation, and then discussed the images again with the same partner or with a new partner in a three-party conversation. Neurotypical participants' language use reflected newly formed representations of which partner was familiar with which images. Participants with amnesia showed evidence of partner-specific audience design in multiparty conversation but it was attenuated, especially when success required rapid alternations between representations of common ground. The findings suggest partial independence of the formation and use of partner-specific representations from the hippocampal-dependent declarative memory system and highlight the unique contributions of the declarative memory system to flexible and dynamic language use.},
  keywords = {Amnesia,Common ground,Discourse,Hippocampus,Memory,Multiparty interaction,read},
  file = {/home/vboyce/Zotero/storage/F9QU97ZX/Yoon et al. - 2023 - Keeping track of who knows what in multiparty conv.pdf;/home/vboyce/Zotero/storage/JXY9JX2Y/S0028393223003147.html}
}

@article{zack1993,
  title = {Interactivity and Communication Mode Choice in Ongoing Management Groups},
  author = {Zack, Michael H},
  year = {1993},
  journal = {Information Systems Research},
  volume = {4},
  number = {3},
  pages = {207--239},
  publisher = {INFORMS}
}

@article{zaslavsky2018,
  title = {Efficient Compression in Color Naming and Its Evolution},
  author = {Zaslavsky, Noga and Kemp, Charles and Regier, Terry and Tishby, Naftali},
  year = {2018},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {31},
  pages = {7937--7942},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1800521115},
  urldate = {2023-07-11},
  abstract = {Significance             Semantic typology documents and explains how languages vary in their structuring of meaning. Information theory provides a formal model of communication that includes a precise definition of efficient compression. We show that color-naming systems across languages achieve near-optimal compression and that this principle explains much of the variation across languages. These findings suggest a possible process for color category evolution that synthesizes continuous and discrete aspects of previous accounts. The generality of this principle suggests that it may also apply to other semantic domains.           ,                             We derive a principled information-theoretic account of cross-language semantic variation. Specifically, we argue that languages efficiently compress ideas into words by optimizing the information bottleneck (IB) trade-off between the complexity and accuracy of the lexicon. We test this proposal in the domain of color naming and show that (               i               ) color-naming systems across languages achieve near-optimal compression; (               ii               ) small changes in a single trade-off parameter account to a large extent for observed cross-language variation; (               iii               ) efficient IB color-naming systems exhibit soft rather than hard category boundaries and often leave large regions of color space inconsistently named, both of which phenomena are found empirically; and (               iv               ) these IB systems evolve through a sequence of structural phase transitions, in a single process that captures key ideas associated with different accounts of color category evolution. These results suggest that a drive for information-theoretic efficiency may shape color-naming systems across languages. This principle is not specific to color, and so it may also apply to cross-language variation in other semantic domains.},
  langid = {english},
  keywords = {read}
}

@book{zipf1949,
  title = {Human Behavior and the Principle of Least Effort: {{An}} Introduction to Human Ecology.},
  author = {Zipf, George},
  year = {1949},
  keywords = {bad,read}
}

@misc{zotero-25581,
  title = {The {{Slow Development}} of {{Real-Time Processing}}: {{Spoken-Word Recognition}} as a {{Crucible}} for {{New Thinking About Language Acquisition}} and {{Language Disorders}} - {{Bob McMurray}}, {{Keith S}}. {{Apfelbaum}}, {{J}}. {{Bruce Tomblin}}, 2022},
  urldate = {2025-01-21},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/09637214221078325},
  keywords = {read},
  file = {/home/vboyce/Zotero/storage/4U5EPBG9/09637214221078325.html}
}
